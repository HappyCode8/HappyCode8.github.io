# 事务

## 事务特性

A: 原子性（Atomicity）：要么全做，要么全不做

C: 一致性（Consistency）：所有事务在事务执行前后对于一个数据的读取结果都是相同的

I: 隔离性（Isolation）：最终提交前对其它事务不可见

D: 持久性（Durability）：一旦提交，修改会永远保存

只有满足一致性结果才是正确的；无并发时串行执行满足原子性就一定满足一致性；并发时还需要满足隔离性才能满足一致性；持久性是为了应对系统崩溃

## 并发一致性问题

- 丢失修改：两个事务在commit前先后修改，后边会覆盖前边的
- 读脏数据：A事务修改后但是没commit,B事务读了但是A事务回滚了
- 不可重复读：A读->B改->A再读，A两次不一样
- 幻读：不可重读的一种，A读一片范围->B插入->A再读，两次行数不一样

并发可以通过封锁实现，但是封锁需要用户自己控制相当复杂，数据库提供了事务隔离级别来解决

## 封锁

- 写锁：加此锁可以读取和更新，加锁期间别的事务不能对A加任何锁
- 读锁：加此锁只能读，加锁期间其余事务可以加读锁，不能加写锁
- 意向锁：意向锁都是表锁，加读锁前必须先获得意向读锁或更强的锁，加写锁前必须先获得意向写锁

三级封锁协议

- 一级封锁协议

  改数据时必须先加写锁直到事务结束释放，解决丢失修改问题，因为加写锁后就不能两个事务同时改了

- 二级封锁协议

  一级基础上，读时必须加读锁，读完马上释放，解决读脏数据，加读锁后读写隔离开了

- 三级封锁协议

  二级基础上，读时加读锁，直到事务结束才释放，解决不可重读

两段锁协议

加锁和解锁分为两个阶段进行，事务

# 实际开发可copy
## 建表
```sql
CREATE TABLE `ai_sco_day_analyse` (
   `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增主键',
   `template_id` varchar(64) NOT NULL DEFAULT '' COMMENT '机器人id',
   `call_date` date NOT NULL DEFAULT '0000-00-00' COMMENT '日期',
   `template_version` varchar(16) NOT NULL DEFAULT '' COMMENT '机器人版本',
   `total_count` int(11) NOT NULL DEFAULT '0' COMMENT '通话总数',
   `through_count` int(11) NOT NULL DEFAULT '0' COMMENT '接通总数',
   `first_round_not_hangup_count` int(11) NOT NULL DEFAULT '0' COMMENT '首轮未挂断总数',
   `cooperate_count` int(11) NOT NULL DEFAULT '0' COMMENT '配合数',
   `success_count` int(11) NOT NULL DEFAULT '0' COMMENT '成功数',
   `see_through_count` int(11) NOT NULL DEFAULT '0' COMMENT '识破数',
   `nlu_distinguish_count` int(11) NOT NULL DEFAULT '0' COMMENT 'nlu实际识别的query数',
   `nlu_eff_count` int(11) NOT NULL DEFAULT '0' COMMENT 'nlu可识别query数',
   `antipathy_count` int(11) NOT NULL DEFAULT '0' COMMENT '反感数',
   `talking_time_len` int(11) NOT NULL DEFAULT '0' COMMENT '通话时长',
   `insert_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '本条记录创建时间',
   `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '本条记录修改时间',
   `is_visible` tinyint(1) NOT NULL DEFAULT '1',
   PRIMARY KEY (`id`),
   UNIQUE KEY `idx_call_date_tenant_id` (`call_date`,`template_id`,`template_version`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4

select bot_id,
       bot_name,
       case when call_count>=100000                      then '价值高'
            when call_count<100000 and call_count>=10000 then '价值中'
            else '价值低'
             end as bot_value,
       case when nlu_distinguish_count_detail/nlu_eff_count_detail>=0.9 and nlu_distinguish_count_mark/nlu_eff_count_mark>=0.9                          then 'B'
            when nlu_distinguish_count_detail/nlu_eff_count_detail>=0.9 and (nlu_distinguish_count_mark/nlu_eff_count_mark<0.9 or nlu_eff_count_mark=0) then 'C'
            else 'D'
             end as bot_rank
  from us.yoona_bot_level_stastics
 where create_date BETWEEN '$$begindate' and '$$enddate'
```

# SQL优化

1. 最左匹配

   ```sql
   KEY `idx_shopid_orderno` (`shop_id`,`order_no`)
   select * from _t where orderno=''
   查询匹配从左往右匹配，要使用order_no走索引，必须查询条件携带shop_id或者索引(shop_id,order_no)调换前后顺序
   ```

2. 隐式转换

   ```sql
   KEY `idx_mobile` (`mobile`)
   select * from _user where mobile=12345678901
   mobile是字符类型，使用了数字，应该使用字符串匹配，否则MySQL会用到隐式替换，导致索引失效。
   ```

3. 大分页

   ```sql
   KEY `idx_a_b_c` (`a`, `b`, `c`)
   select * from _t where a = 1 and b = 2 order by c desc limit 10000, 10;
   对于大分页的场景，可以优先让产品优化需求，如果没有优化的，有如下两种优化方式：
   一种是把上一次的最后一条数据，也即上面的c传过来，然后做“c < xxx”处理，但是这种一般需要改接口协议，并不一定可行；‘
   另一种是采用延迟关联的方式进行处理，减少SQL回表，但是要记得索引需要完全覆盖才有效果，SQL改动如下：
   select t1.* from _t t1, (select id from _t where a = 1 and b = 2 order by c desc limit 10000, 10) t2 where t1.id = t2.id;
   ```

4. in+order by

   ```sql
   KEY `idx_shopid_status_created` (`shop_id`, `order_status`, `created_at`)
   select * from _order where shop_id = 1 and order_status in (1, 2, 3) order by created_at desc limit 10
   
   in查询在MySQL底层是通过n*m的方式去搜索，类似union，但是效率比union高。
   
   in查询在进行cost代价计算时（代价 = 元组数 * IO平均值），是通过将in包含的数值，一条条去查询获取元组数的，因此这个计算过程会比较的慢，所以MySQL设置了个临界值(eq_range_index_dive_limit)，5.6之后超过这个临界值后该列的cost就不参与计算了。因此会导致执行计划选择不准确。默认是200，即in条件超过了200个数据，会导致in的代价计算存在问题，可能会导致Mysql选择的索引不准确。
   
   可以(order_status, created_at)互换前后顺序，并且调整SQL为延迟关联。
   ```

5. 范围查询阻断，后续字段不能走索引

   ```sql
   KEY `idx_shopid_created_status` (`shop_id`, `created_at`, `order_status`)
   select * from _order where shop_id = 1 and created_at > '2021-01-01 00:00:00' and order_status = 10
   范围查询还有in between
   ```

6. 不等于、不包含不能用到索引的快速搜索

   ```sql
   在索引上，避免使用NOT、!=、<>、!<、!>、NOT EXISTS、NOT IN、NOT LIKE等。
   ```

7. 优化器选择不使用索引

   ```sql
   如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时（一般是20%左右），优化器会选择通过聚集索引来查找数据。
   select * from _order where  order_status = 1
   查询出所有未支付的订单，一般这种订单是很少的，即使建了索引，也没法使用索引。
   ```

8. 复杂查询

   ```sql
   如果是统计某些数据，可能改用数仓进行解决
   如果是业务上就有那么复杂的查询，可能就不建议继续走SQL了，而是采用其他的方式进行解决，比如使用ES等进行解决
   ```

9. asc和desc混用

   ```sql
   desc 和asc混用时会导致索引失效。
   ```

10. 大数据

    ```sql
    对于推送业务的数据存储，可能数据量会很大，如果在方案的选择上，最终选择存储在MySQL上，并且做7天等有效期的保存。
    那么需要注意，频繁的清理数据，会照成数据碎片，需要联系DBA进行数据碎片处理。
    ```

# MySQL中使用json

1. 数据字段设置为json

   ```sql
   CREATE TABLE UserLogin (
       userId BIGINT NOT NULL,
       loginInfo JSON,
       PRIMARY KEY(userId)
   );
   ```

2. 检索json

   ```sql
   SELECT
       userId,
       JSON_UNQUOTE(JSON_EXTRACT(loginInfo,"$.cellphone")) cellphone,
       JSON_UNQUOTE(JSON_EXTRACT(loginInfo,"$.wxchat")) wxchat
   FROM UserLogin;
   简化版：
   SELECT 
       userId,
       loginInfo->>"$.cellphone" cellphone,
       loginInfo->>"$.wxchat" wxchat
   FROM UserLogin;
   ```

3. 在json某个字段上建立索引

   ```sql
   ALTER TABLE UserLogin ADD COLUMN cellphone VARCHAR(255) AS (loginInfo->>"$.cellphone");
   
   ALTER TABLE UserLogin ADD UNIQUE INDEX idx_cellphone(cellphone);
   
   上述 SQL 首先创建了一个虚拟列 cellphone，这个列是由函数 loginInfo->>"$.cellphone" 计算得到的。然后在这个虚拟列上创建一个唯一索引 idx_cellphone
   
   当然，我们可以在一开始创建表的时候，就完成虚拟列及函数索引的创建。如下表创建的列 cellphone 对应的就是 JSON 中的内容，是个虚拟列；uk_idx_cellphone 就是在虚拟列 cellphone 上所创建的索引。
   
   CREATE TABLE UserLogin (
       userId BIGINT,
       loginInfo JSON,
       cellphone VARCHAR(255) AS (loginInfo->>"$.cellphone"),
       PRIMARY KEY(userId),
       UNIQUE KEY uk_idx_cellphone(cellphone)
   );
   ```

4. 实例

   ```sql
   用户画像库表，不用json
   用户    |标签                                   |
   +-------+---------------------------------------+
   |David  |80后 ； 高学历 ； 小资 ； 有房 ；常看电影   |
   |Tom    |90后 ；常看电影 ； 爱外卖                 |
   
   缺点：不好搜索特定画像的用户，另外分隔符也是一种自我约定，在数据库中其实可以任意存储其他数据，最终产生脏数据。
   
   CREATE TABLE UserTag (
       userId bigint NOT NULL,
       userTags JSON,
       PRIMARY KEY (userId)
   );
   
   INSERT INTO UserTag VALUES (1,'[2,6,8,10]');
   INSERT INTO UserTag VALUES (2,'[3,10,12]');
   
   MySQL 8.0.17 版本开始支持 Multi-Valued Indexes，用于在 JSON 数组上创建索引，并通过函数 member of、json_contains、json_overlaps 来快速检索索引数据。所以你可以在表 UserTag 上创建 Multi-Valued Indexes
   
   ALTER TABLE UserTag
   ADD INDEX idx_user_tags ((cast((userTags->"$") as unsigned array)));
   
   如果想要查询用户画像为常看电影的用户，可以使用函数 MEMBER OF：
   SELECT * FROM UserTag WHERE 10 MEMBER OF(userTags->"$")
   
   如果想要查询画像为 80 后，且常看电影的用户，可以使用函数 JSON_CONTAINS：
   SELECT * FROM UserTag WHERE JSON_CONTAINS(userTags->"$", '[2,10]')
   
   如果想要查询画像为 80 后、90 后，且常看电影的用户，则可以使用函数 JSON_OVERLAP：
   SELECT * FROM UserTag WHERE JSON_OVERLAPS(userTags->"$", '[2,3,10]')
   
   
   ```

   
