# 字符串匹配算法

- BF（Brute Force）算法：暴力破解
  - 字符串短的时候用，代码实现简单
- RK算法
  - 将主串中每一个子串长度的子串求哈希然后比较，可以降低复杂度到O(n)
- BM算法与KMP算法
  - 较复杂，主要要根据子串自身的一些特征然后在不匹配时往后滑动多位

# 高级数据结构

## 拓扑排序

## 最短路径

- Dijkstra
-  Bellford 
- Floyd

## 位图

- 布隆过滤器

## 基于概率的统计

过滤垃圾短信，可以有3种方法

- 基于黑名单
- 规则
- 朴素贝叶斯

## 向量空间

- 基于相似用户做推荐

  >1. 把人听的歌作为向量
  >2. 把向量差距不大的人，看作口味相似的用户
  >3. 遍历所有的用户，对比每个用户跟被推荐者口味相似的用户，并且设置一个阈值，如果你和某个用户共同喜爱的歌曲个数超过这个阈值，我们就把这个用户看作跟你口味相似的用户，把这个用户喜爱但你还没听过的歌曲，推荐给你

- 基于相似歌曲做推荐

  >1. 把听了歌的人作为向量
  >2. 计算歌曲之间的相似度
  >3. 在用户已经听过的歌曲中，找出他喜爱程度较高的歌曲。然后，我们找出跟这些歌曲相似度很高的其他歌曲，推荐给他

## A*算法

- 寻路算法
- 不能像 Dijkstra 算法那样，找到最短路径

## LSM Tree

- Log Structure Merge Tree
- 这种结构的写入，全部都是以Append的模式追加，不存在删除和修改。当然有得就有舍，这种结构虽然大大提升了数据的写入能力，却是以牺牲部分读取性能为代价，故此这种结构通常适合于写多读少的场景。故LSM被设计来提供比传统的B+树或者ISAM更好的写操作吞吐量，通过消去随机的本地更新操作来达到这个目标。这里面最典型的例子就属于Kakfa了
- 支持高写，B+树支持高读

## 时间轮

延时队列的底层实现

- JDK 中的 DelayedQueue
- Redis 中 ZSET
- 时间轮

## pageRank

## Raft

## UUID

## 一致性哈希

## Trie树（字典树）

- 存储

  ```java
  class TrieNode {
    char data;
    TrieNode children[26];//只有26个字母的字典树，不存在的对应置空
  }
  ```

- 耗内存

- 使用场景

  Trie 树不适合精确匹配查找，这种问题更适合用散列表或者红黑树来解决，Trie 树比较适合的是查找前缀匹配的字符串

## AC自动机

- 单模式串匹配算法

  在一个模式串和一个主串之间进行匹配，也就是说，在一个主串中查找一个模式串。BF 算法、RK 算法、BM 算法、KMP 算法等字符串匹配算法

- 多模式串匹配算法

  在多个模式串和一个主串之间做匹配，也就是说，在一个主串中查找多个模式串。Trie 树。

- AC自动机算法（Aho-Corasick）

  AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了。

  ```java
  public class AcNode {
    public char data; 
    public AcNode[] children = new AcNode[26]; // 字符集只包含a~z这26个字符
    public boolean isEndingChar = false; // 结尾字符为true
    public int length = -1; // 当isEndingChar=true时，记录模式串长度
    public AcNode fail; // 失败指针
    public AcNode(char data) {
      this.data = data;
    }
  }
  ```

DFA（确定有穷自动机）

```java
public class Solution {

    public static Map<String, Object> dictionaryMap = new HashMap<>();
    /**
     * 生成关键词字典库
     * @param words
     * @return
     */
    public static void initMap(Collection<String> words) {
        if (words == null) {
            System.out.println("敏感词列表不能为空");
            return ;
        }
        // map初始长度words.size()，整个字典库的入口字数(小于words.size()，因为不同的词可能会有相同的首字)
        Map<String, Object> map = new HashMap<>(words.size());
        // 遍历过程中当前层次的数据
        Map<String, Object> curMap = null;
        Iterator<String> iterator = words.iterator();

        while (iterator.hasNext()) {
            String word = iterator.next();
            curMap = map;
            int len = word.length();
            for (int i =0; i < len; i++) {
                // 遍历每个词的字
                String key = String.valueOf(word.charAt(i));
                // 当前字在当前层是否存在, 不存在则新建, 当前层数据指向下一个节点, 继续判断是否存在数据
                Map<String, Object> wordMap = (Map<String, Object>) curMap.get(key);
                if (wordMap == null) {
                    // 每个节点存在两个数据: 下一个节点和isEnd(是否结束标志)
                    wordMap = new HashMap<>(2);
                    wordMap.put("isEnd", "0");
                    curMap.put(key, wordMap);
                }
                curMap = wordMap;
                // 如果当前字是词的最后一个字，则将isEnd标志置1
                if (i == len -1) {
                    curMap.put("isEnd", "1");
                }
            }
        }
        dictionaryMap = map;
    }

    /**
     * 搜索文本中某个文字是否匹配关键词
     * @param text
     * @param beginIndex
     * @return
     */
    private static int checkWord(String text, int beginIndex) {
        if (dictionaryMap == null) {
            throw new RuntimeException("字典不能为空");
        }
        boolean isEnd = false;
        int wordLength = 0;
        Map<String, Object> curMap = dictionaryMap;
        int len = text.length();
        // 从文本的第beginIndex开始匹配
        for (int i = beginIndex; i < len; i++) {
            String key = String.valueOf(text.charAt(i));
            // 获取当前key的下一个节点
            curMap = (Map<String, Object>) curMap.get(key);
            if (curMap == null) {
                break;
            } else {
                wordLength ++;
                if ("1".equals(curMap.get("isEnd"))) {
                    isEnd = true;
                }
            }
        }
        if (!isEnd) {
            wordLength = 0;
        }
        return wordLength;
    }

    /**
     * 获取匹配的关键词和命中次数
     * @param text
     * @return
     */
    public static Map<String, Integer> matchWords(String text) {
        Map<String, Integer> wordMap = new HashMap<>();
        int len = text.length();
        for (int i = 0; i < len; i++) {
            int wordLength = checkWord(text, i);
            if (wordLength > 0) {
                String word = text.substring(i, i + wordLength);
                // 添加关键词匹配次数
                if (wordMap.containsKey(word)) {
                    wordMap.put(word, wordMap.get(word) + 1);
                } else {
                    wordMap.put(word, 1);
                }
                i += wordLength - 1;
            }
        }
        return wordMap;
    }

    public static void main(String[] args) {
        // 初始化 敏感词 列表
        List<String> list = new ArrayList<>();
        list.add("冰毒");
        list.add("特朗普");
        initMap(list);
        // 待查询文本
        String content="我是一个好人，买卖冰毒是违法的特朗普";
        // 匹配文本
        Map<String, Integer> map = matchWords(content);
        System.out.println(map);
    }
}
```

## 并查集

- 前言

用于解决动态连通性问题，能动态连接两个点，并且判断两个点是否连通。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/02943a90-7dd4-4e9a-9325-f8217d3cc54d.jpg)



|              方法               |           描述            |
| :-----------------------------: | :-----------------------: |
|            UF(int N)            | 构造一个大小为 N 的并查集 |
|    void union(int p, int q)     |     连接 p 和 q 节点      |
|         int find(int p)         | 查找 p 所在的连通分量编号 |
| boolean connected(int p, int q) | 判断 p 和 q 节点是否连通  |

```java
public abstract class UF {

    protected int[] id;

    public UF(int N) {
        id = new int[N];
        for (int i = 0; i < N; i++) {
            id[i] = i;
        }
    }

    public boolean connected(int p, int q) {
        return find(p) == find(q);
    }

    public abstract int find(int p);

    public abstract void union(int p, int q);
}
```

- Quick Find

可以快速进行 find 操作，也就是可以快速判断两个节点是否连通。

需要保证同一连通分量的所有节点的 id 值相等，就可以通过判断两个节点的 id 值是否相等从而判断其连通性。

但是 union 操作代价却很高，需要将其中一个连通分量中的所有节点 id 值都修改为另一个节点的 id 值。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/0972501d-f854-4d26-8fce-babb27c267f6.jpg)



```java
public class QuickFindUF extends UF {

    public QuickFindUF(int N) {
        super(N);
    }


    @Override
    public int find(int p) {
        return id[p];
    }


    @Override
    public void union(int p, int q) {
        int pID = find(p);
        int qID = find(q);

        if (pID == qID) {
            return;
        }

        for (int i = 0; i < id.length; i++) {
            if (id[i] == pID) {
                id[i] = qID;
            }
        }
    }
}
```

- Quick Union

可以快速进行 union 操作，只需要修改一个节点的 id 值即可。

但是 find 操作开销很大，因为同一个连通分量的节点 id 值不同，id 值只是用来指向另一个节点。因此需要一直向上查找操作，直到找到最上层的节点。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/11b27de5-5a9d-45e4-95cc-417fa3ad1d38.jpg)



```java
public class QuickUnionUF extends UF {

    public QuickUnionUF(int N) {
        super(N);
    }


    @Override
    public int find(int p) {
        while (p != id[p]) {
            p = id[p];
        }
        return p;
    }


    @Override
    public void union(int p, int q) {
        int pRoot = find(p);
        int qRoot = find(q);

        if (pRoot != qRoot) {
            id[pRoot] = qRoot;
        }
    }
}
```

这种方法可以快速进行 union 操作，但是 find 操作和树高成正比，最坏的情况下树的高度为节点的数目。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/23e4462b-263f-4d15-8805-529e0ca7a4d1.jpg)

- 加权 Quick Union

为了解决 quick-union 的树通常会很高的问题，加权 quick-union 在 union 操作时会让较小的树连接较大的树上面。

理论研究证明，加权 quick-union 算法构造的树深度最多不超过 logN。

![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a9f18f8a-c1ea-422e-aa56-d91716b0f755.jpg)



```java
public class WeightedQuickUnionUF extends UF {

    // 保存节点的数量信息
    private int[] sz;


    public WeightedQuickUnionUF(int N) {
        super(N);
        this.sz = new int[N];
        for (int i = 0; i < N; i++) {
            this.sz[i] = 1;
        }
    }


    @Override
    public int find(int p) {
        while (p != id[p]) {
            p = id[p];
        }
        return p;
    }


    @Override
    public void union(int p, int q) {

        int i = find(p);
        int j = find(q);

        if (i == j) return;

        if (sz[i] < sz[j]) {
            id[i] = j;
            sz[j] += sz[i];
        } else {
            id[j] = i;
            sz[i] += sz[j];
        }
    }
}
```

- 路径压缩的加权 Quick Union

在检查节点的同时将它们直接链接到根节点，只需要在 find 中添加一个循环即可。

- 比较

|            算法            |   union    |    find    |
| :------------------------: | :--------: | :--------: |
|         Quick Find         |     N      |     1      |
|        Quick Union         |    树高    |    树高    |
|      加权 Quick Union      |    logN    |    logN    |
| 路径压缩的加权 Quick Union | 非常接近 1 | 非常接近 1 |

## 2,3树

## 2,3,4树

## 红黑树

## 单调栈

## 线段树

## 树状数组

## 后缀数组

```
一,顺序表
线性枚举 前缀和 双指针 二分枚举 三分枚举 离散化 冒泡排序 选择排序快速排序 插入排序希尔排序 归并排序 堆排序 基数排序 计数排序 模拟 贪心
二,链表
单向链表 双向链表
三,栈
LIFO栈（后进先出）单调栈 
四,队列
FLFO队列（先进先出） 双端队列 单调队列
五,字符串
KMP 字典树 马拉车 AC自动机 后缀数组 BM
六,树
二叉树 二叉搜索树 AVL树 线段树 霍夫曼树 堆 红黑树 伸展树 左偏树 Treap B+树 树链剖分 
七,图
二分图 最短路 最小生成树 最近公共祖先 深度优先搜索 强连通分量 双连通分量 2-sat 欧拉回路 
哈密尔顿回路 迭代加深 广度优先搜索 拓扑排序 A* 稳定婚姻 双向广搜 查分约束 并查集 哈希表 跳跃表 树状数组 最大流 
八,动态规划
递推 线性DP 记忆化搜索 背包问题 树形DP 区间DP 数位DP 状压DP 
```

# 业务算法

## 短网址

第一种实现思路是通过哈希算法生成短网址。我们采用计算速度快、冲突概率小的 MurmurHash 算法，并将计算得到的 10 进制数，转化成 62 进制表示法，进一步缩短短网址的长度。对于哈希算法的哈希冲突问题，我们通过给原始网址添加特殊前缀字符，重新计算哈希值的方法来解决。

第二种实现思路是通过 ID 生成器来生成短网址。我们维护一个 ID 自增的 ID 生成器，给每个原始网址分配一个 ID 号码，并且同样转成 62 进制表示法，拼接到短网址服务的域名之后，形成最终的短网址。

## 高性能队列Disruptor

Disruptor 采用了“两阶段写入”的方法。在写入数据之前，先加锁申请批量的空闲存储单元，之后往队列中写入数据的操作就不需要加锁了，写入的性能因此就提高了。Disruptor 对消费过程的改造，跟对生产过程的改造是类似的。它先加锁申请批量的可读取的存储单元，之后从队列中读取数据的操作也就不需要加锁了，读取的性能因此也就提高了。

## 文本差分

## Gossip协议

## Raft协议
