## 数仓为什么要分层

1. **维护成本降低**。试想一个上千行的代码从头一点点理解，有问题需要修改时的维护成本是相当高的，而且很容易出错。
2. **隔离变化**。试想一下，如果某天需要更换数据源A为C，只需要修改任务1的代码即可，对下游的可以做到屏蔽变化，无感知。
3. **增加了复用性**，**进而带来一致性的提升和开发效率的提升**。
4. **持久化可以用空间换时间，节省计算资源**。
5. **提升数据安全**。不管是对表还是对视图，都可以按照不同规则把权限开放给不同的人，保证数据流通的前提下提升数据安全。
6. **统一建设思路**。明确职责，明确开发的先后顺序，让不同的开发人员开发思路更加统一，以便不同的人员可以更好的协作，真正出现问题也更好的定位到哪一层。
7. **血缘清晰**。通过命名规范区分不同的层，可以使开发时都沿着同一个顺序进行生产，血缘关系更加清晰，避免开发和调度时的循环依赖。

## 两种架构模式

- **Lambda架构**
  
  此架构的思想是将离线计算和实时计算分离，包含三个模块：
  
  1. **Batch Layer（批处理层）**：对历史的全量数据进行批处理，准确性高但时效性低（一般有小时级或天级延迟）；
  2. **Real-time Layer（实时层）**：对短期的增量数据进行流式处理或微批处理，实现秒级或分钟级的低延迟，弥补批处理层的滞后性；
  3. **Serving Layer（服务层）**：汇总以上两层模块的处理结果，暴露给外部服务调用。
  
  业界的大多数数仓采用的是**Spark/Hive离线计算引擎 + Storm/Flink实时计算引擎 + OLAP/OLTP存储引擎**的组件选型，这本质上就是Lambda架构。

- **Kappa架构**
  
  此架构的思想是离线计算和实时计算合二为一，包含两个模块：
  
  1. **Real-time Layer（实时层）**：扩展了Lambda架构的实时层，既处理短期增量数据，也处理历史全量数据，兼顾准确性和时效性；
  2. **Serving Layer（服务层）**：与Lambda架构相同，收集实时层的计算结果并对外提供服务。
  
  Kappa架构适用于侧重实时数据处理的场景，典型的技术选型是**Kafka消息中间件 + Flink实时**计算引擎，业界也有越来越多的领域开始基于Kappa架构建设数仓。
  
  | 架构方式     | 优点                                        | 缺点                                                                 |
  |:-------- |:----------------------------------------- |:------------------------------------------------------------------ |
  | Lambda架构 | 离线和实时计算分别采用最合适的技术选型，同时具备高准确性和低延迟性离线数据容易订正 | 需要搭建两套计算引擎，维护成本高需要确保两套引擎处理逻辑和结果完全一致，难度较高                           |
  | Kappa架构  | 只需搭建一套引擎，维护成本低无需合并离线和实时处理结果               | 实时引擎处理历史大量数据时，难以达到与离线引擎相同的性能在进行复杂逻辑计算时，实时引擎可能会存在数据丢失、计算偏差等问题，准确性较差 |
  
  总结来说，Lambda架构是一种传统的、较为稳妥的方式，如果对大量数据的处理有很高的准确性要求，同时又可以容忍较高的延迟，可以选用此架构。Kappa架构更偏重于对实时数据的处理能力，如果追求数据的时效性，可以尝试此架构。

## 数据分层

1. **ODS层（Operation Data）**：原始数据（包含业务DB、业务日志、第三方采买等来源）
   
   > 命名：ods_表名 _单分区增量全量标识（inc/full）,例：ods_order_info_inc，ods_order_info_full
   > 
   > 压缩：gzip压缩（压缩比较高）
   > 
   > json数据：可以一行对应的全存，也可以对应的用struct<A字段：数据类型，B字段：数据类型>代表map，array<数据类型>代表array

2. **DWD层（Detail）**：与业务有关的的维度引用与过程度量，列少行多增长快
   
   > 命名：dwd_ 数据域_ 表名_ 单分区增量全量标识（inc/full/acc 增/全/累积）
   > 
   > 压缩：orc存储+snappy压缩

3. **DWS（Summary）层**：它对DW层的数据进一步加工，生成轻度汇总的非明细数据。这一层的数据主要面向后续的业务查询、OLAP分析等；
   
   > 命名：dws_ 数据域_ 表名_ 统计周期（1d,2w等），例：dws_trade_org_cargo_type_order_1d
   > 
   > 假设dws_call_info_1d已经统计到了每天的数据，那么先使用lateral view explode(array(1, 2, 3))炸开，然后按照recent_days进行group by就可以取到最近1、2、3天的数据。其中dt是每一个数据的分区日期，date_sub('$$today',recent_days)是用今天减去每一个炸开的天数，然后比较这两个值，越近的日期保留的越多。
   > 
   > dws_call_info_1d原始数据：
   > 
   > | template_value | dt         | sum_call | through_call |
   > | -------------- | ---------- | -------- | ------------ |
   > | 1              | 2023-07-14 | 1000     | 500          |
   > | 1              | 2023-07-15 | 2000     | 600          |
   > | 1              | 2023-07-16 | 3000     | 700          |
   > 
   > 炸开以后再按照where条件筛选，就可以得到加黑条件的行，然后即可按照recent_days进行汇总：
   > 
   > | template_value | dt             | recent_days | sum_call | through_call |
   > | -------------- | -------------- | ----------- | -------- | ------------ |
   > | 1              | 2023-07-14     | 1           | 1000     | 500          |
   > | 1              | 2023-07-14     | 2           | 1000     | 500          |
   > | **1**          | **2023-07-14** | **3**       | **1000** | **500**      |
   > | 1              | 2023-07-15     | 1           | 2000     | 600          |
   > | **1**          | **2023-07-15** | **2**       | **2000** | **600**      |
   > | **1**          | **2023-07-15** | **3**       | **2000** | **600**      |
   > | **1**          | **2023-07-16** | **1**       | **3000** | **700**      |
   > | **1**          | **2023-07-16** | **2**       | **3000** | **700**      |
   > | **1**          | **2023-07-16** | **3**       | **3000** | **700**      |
   > 
   > ```sql
   > select recent_days,
   >       template_value,
   >       sum(sum_call),
   >       sum(through_call)
   >  from mart_ai_sco.yoona_result lateral view explode(array(1, 2, 3)) tmp as recent_days
   > where dt >=date_sub('$$today',recent_days)
   >   and template_value='1'
   >   group by recent_days,
   >                       template_value
   > ```

4. **ADS层（Application）**：它基于前面三层的数据，计算出数据产品最终使用的结果数据。这一层是高度汇总的最终产出数据，一般会同步到MySQL、ES、Druid等其他OLTP/OLAP存储引擎中供查询分析使用。
   
   > 命名：ads_ 数据域_ 表名

5. **DIM：维度表**
   
   > 命名：dim_表名 _全量或者拉链标识（full/zip），例：dim_order_info_full，dim_order_info_zip
   > 
   > 压缩：经常要查，orc列式存储（查询快）+snappy压缩（压缩速度快）
   > 
   > 维度退化：简单的维度直接放入事实表

除了四层模型外，还有三层模型等其他划分方式，思想都大同小异，遵循“原始数据 -> 基础明细数据 -> 半成品数据 -> 成品数据”的路径进行层次划分。在实际构建数仓时，也需要结合具体的业务场景，灵活制定分层结构。

分层模型的好处显而易见，主要有以下几点：

1. **提升可维护性**：将复杂的数据生产逻辑拆解成各层的子逻辑，便于维护和定位问题；
2. **简化血缘关系**：只允许上层依赖下层，不允许反向依赖，避免混乱的数据流向；
3. **减少重复开发**：通过主题建模，开发一些通用的中间数据（例如维度表），实现复用；
4. **屏蔽原始数据**：通过设计良好的ODS层，数仓使用方不必了解原始数据的细节和异常即可接入。

## 架构过程

1. 首先，综合考虑数据时效性要求、准确性要求、计算逻辑复杂度、成本要求等因素，选取Lambda架构或Kappa架构；
2. 然后，借鉴经典的四层/三层模型，结合业务主题、业务复杂度、数据特点、数据规模等因素，构建业务数仓分层体系；
3. 最后，在建模理论（通常是维度建模思想）的指导下设计数据表，确定更细粒度的数据结构。至此数仓的架构设计工作基本完成。

## 表模型

[参考](https://blog.csdn.net/weixin_40983094/article/details/110001082)

1. 全量表
   
   全覆盖更新，不分区

2. 增量表
   
   按时间分区，每个时间只同步那些增加或者修改的数据

3. 快照表
   
   按时间分区，每个分区都同步全量的数据

4. 拉链表
   
   不分区，每天把变动的数据附加到表中同时指明每一条数据的生命周期
   
   > 构建流水表的过程是用增量表与全量表联表处理再并入增量表
   
   假如有一张用户地址记录表：
   
   | ID  | 地址  |
   | --- | --- |
   | 1   | 甘肃  |
   | 2   | 河南  |
   | 3   | 湖北  |
   
   初始全量装载：
   
   | ID  | 地址  | 开始时间       | 结束时间       |
   | --- | --- | ---------- | ---------- |
   | 1   | 甘肃  | 2023-01-01 | 9999-12-31 |
   | 2   | 河南  | 2023-01-01 | 9999-12-31 |
   | 3   | 湖北  | 2023-01-01 | 9999-12-31 |
   
   第二天2发生了修改，4、5增加了：
   
   | ID    | 地址     |
   | ----- | ------ |
   | 1     | 甘肃     |
   | **2** | **河北** |
   | 3     | 湖北     |
   | **4** | **山东** |
   | **5** | **江苏** |
   
   将地址的变化表（2,4,5组成的表）与之前的拉链表合并得到新的拉链表
   
   | ID  | 地址  | 开始时间       | 结束时间       |
   | --- | --- | ---------- | ---------- |
   | 1   | 甘肃  | 2023-01-01 | 9999-12-31 |
   | 2   | 河南  | 2023-01-01 | 2023-01-01 |
   | 2   | 河北  | 2023-01-02 | 9999-12-31 |
   | 3   | 湖北  | 2023-01-01 | 9999-12-31 |
   | 4   | 山东  | 2023-01-02 | 9999-12-31 |
   | 5   | 江苏  | 2023-01-02 | 9999-12-31 |
   
   基于拉链表可以按需生产这么几张表：
   
   > 1. 分区是9999-12-31的是最新用户地址表
   > 2. 分区是当日的表示的是最后有效的用户地址表（加1天就失效）
   
   首日装载的sql
   
   ```sql
   insert overwrite table dim_user_address_zip partition (dt = '9999-12-31')
   select 
               id,
               address,
          '2023-01-01' start_date,
          '9999-12-31' end_date
   from ods_user_address_inc
   where dt = '2023-01-01'
   ```
   
   每日装载的sql形成的新拉链表，然后每日装载的拉链表可以再分区到全量最新以及过期分区
   
   ```sql
   set hive.exec.dynamic.partition.mode=nonstrict; insert overwrite table dim_user_address_zip partition (dt)
   SELECT   id,-- 按照id分区以后如果是第一行，那么结束日期设为9999，否则是当前日期减一天
            address,
            if(rk = 1, end_date, date_add('2023-01-02', -1)) end_date, 
            if(rk = 1, end_date, date_add('2023-01-02', -1)) dt
   FROM 
       (SELECT id,-- 合并后的表按照id分区按照start_date降序
               address,
               row_number() OVER (partition by id ORDER BY start_date desc) rk
       FROM 
           (SELECT id,-- 原来的分区9999的最新地址
                   address,
                   start_date,
                   end_date
           FROM dim_user_address_zip
           WHERE dt = '9999-12-31'
   
           UNION
   
           SELECT id,-- 增量表里边分区以后每个取第一行组成新表
                  address,
                  '2023-01-02' start_date, 
                  '9999-12-31' end_date
           FROM 
                   (SELECT address,-- 增量表
                           row_number() OVER (partition by id ORDER BY  ts desc) rn
                   FROM ods_user_address_inc
                   WHERE dt = '2023-01-02') inc
           WHERE rn = 1 
           ) union_info 
       ) with_rk; 
   ```

5. 流水表
   
   存储用户的每次操作

## 事实

1. 事务事实表：事务事实表描述业务过程事务层面的事实，每条记录代表一个事务事件，保留事务事件活动的原始内容。

2. 周期快照事实表：周期快照事实表以具有规律性、可预见的时间间隔产生快照来记录事实，每行代表某个时间周期的一条记录，记录的事实是时间周期内的聚集事实值或状态度量。

3. 累积快照事实表：累积快照事实表覆盖一个事务从开始到结束之间所有的关键事件，覆盖事务的整个生命周期，通常具有多个日期字段来记录关键事件时间点。
   
   > 1. 通过日期分区表实现累积快照事实表时，每个分区代表了一个时间段，通常以天为单位。每天的分区存储昨天的数据以及当天的增量数据的结果，并且不断累积所有的历史状态。数据量增大时，使用这种实现方式会导致**全量表膨胀**，并且会**存储大量永远不更新的冷数据**，严重影响性能。因此这种实现方式更**适合于数据量较少的情况**
   > 2. 使用日期分区表实现累积快照事实表的另一种方式是，**通过推测数据的最长生命周期来分区**，周期内的数据存储在分区表中，周期外的冷数据存储到归档表中。这种方式需要在实际业务中推测数据的最长生命周期，这可能会导致一些数据丢失或记录不全的情况发生，需要仔细权衡业务需求和数据的可靠性。另外，由于**需要保留多天的分区数据**，存储消耗依然较大
   > 3. **以业务实体的结束时间作为分区的依据**，每天的分区存放当天结束的数据。设计一个时间非常大的分区，例如9999-12-31，存放截止当前未结束的数据。这样，已结束的数据存放到相应分区，而存放未结束数据的分区数据量也不会很大，ETL性能好。

## 维度

1. 全量快照维度表：每天一次，每天保存一份全量数据表
2. 维度拉链表：包含数据、开始日期、结束日期

### 维度建模

1. **星型模型：**较为简单，通常不能满足实际业务领域复杂场景的要求；
2. **雪花模型：**在星型模型的基础上，扩展了多层级的维表结构，消除了维表中的冗余，更好满足了范式设计要求。但其缺点在于结构较为复杂，开发难度大，然而其解决的冗余问题在数据仓库领域并不严重；
3. **星座模型：**在星型模型基础上，扩展了多事实表、共享维度表的结构，能更好地描述复杂业务场景下事件与实体的关系。

在实际数仓设计中，较多采用星座模型，存在多个不同主题的事实表，以及多个可共享的维度表。并在表结构的设计上采用适当冗余的反范式方法，简化用户查询。
