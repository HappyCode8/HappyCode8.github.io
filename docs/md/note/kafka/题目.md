# kafka的消费语义

>至少一次：at-least-once, 关闭offset自动提交功能，消费完了但是没发确认，开机重消费，至少不会丢数据，客户端可以自己去重。
>
>至多一次：at-most-once，开启自动提交offset的功能，下一次再消费的时候就会认为offset已经成功了，直接丢弃消息。就会造成丢数据。
>
>仅一次：exactly-once，开启自动开启offset提交的功能，可以开启consumer.seek()方法，相当于自己处理分区和offset，可以在此基础上开启事务，保持原子性，只有数据库保存成功再提交offset，保证两者同时成功。

# Kafka为什么这么快

> - partition 并行处理
>
>   一方面，由于不同 Partition 可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理。另一方面，由于 Partition 在物理上对应一个文件夹，即使多个 Partition 位于同一个节点，也可通过配置让同一节点上的不同 Partition 置于不同的磁盘上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势。
>
> - 顺序写磁盘，充分利用磁盘特性
>
>   **Kafka 中每个分区是一个有序的，不可变的消息序列**，新的消息不断追加到 partition 的末尾，这个就是顺序写。
>
> - 利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率
>
>   Broker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了 `flush.messages` 和 `flush.ms` 两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。
>
> - 采用了零拷贝技术
>
>   1. 网络数据持久化到磁盘 (Producer 到 Broker)
>   2. 磁盘文件通过网络发送（Broker 到 Consumer)
>
> - Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入
>
>   Kafka 的客户端和 broker 还会在通过网络发送数据之前，在一个批处理中累积多条记录 (包括读和写)。记录的批处理分摊了网络往返的开销，使用了更大的数据包从而提高了带宽利用率。
>
> - Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗
>
>   Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。

