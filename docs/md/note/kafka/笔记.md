# 第1章　欢迎来到Kafka Streams

- 如何在一个集群中分发数据以达到易处理的规模

  切分数据以达到数据最小化

- 使用键/值对和分区将分布式数据分组在一起

  使用键/值对的键来对数据进行分区，比如int partition = key.hashCode() % numberOfPartitions;

- 利用副本来容忍故障而不是避免故障

- 流式处理与批处理的例子

  流式处理：金融诈骗预防、入侵检测、大型赛事、金融业

  批处理：经济预测、学校实施课程的改变效果

  配套源码：https://github.com/bbejeck/kafka-streams-in-action

# 第2章 Kafka快速指南

- Kafka是一个消息代理

  Kafka将消息存储在主题中，并从主题检索消息。消息的生产者和消费者之间不会直接连接。此外，Kafka并不会保持有关生产者和消费者的任何状态，它仅作为一个消息交换中心。主题可以视为按名称分隔的日志。

- Kafka是一个日志

  Kafka主题底层的技术是日志，它是Kafka追加输入记录的文件。kafka的日志是一种只能追加、完全按照时间顺序排列的记录序列。

- Kafka日志工作原理

  当安装Kafka时，其中一个配置项是log.dir，该配置项用来指定Kafka存储日志数据的路径。每个主题都映射到指定日志路径下的一个子目录。子目录数与主题对应的分区数相同，目录名格式为“主题名_分区编号”。每个目录里面存放的都是用于追加传入消息的日志文件，一旦日志文件达到某个规模（磁盘上的记录总数或者记录的大小），或者消息的时间戳间的时间间隔达到了所配置的时间间隔时，日志文件就会被切分，传入的消息将会被追加到一个新的日志文件中

  >logs
  >
  > logs/topicA_0   A有1个分许
  >
  > logs/topicB_0   B有3个分区
  >
  > logs/topicB_1
  >
  > logs/topicB_2

- Kafka和分区

  分区是Kafka设计的一个重要部分，它对性能来说必不可少。分区保证了同一个键的数据将会按序被发送给同一个消费者。

  对主题作分区的本质是将发送到主题的数据切分到多个平行流之中，这是Kafka能够实现巨大吞吐量的关键。我们解释过每个主题就是一个分布式日志，每个分区类似于一个它自己的日志，并遵循相同的规则。Kafka将每个传入的消息追加到日志末尾，并且所有的消息都严格按时间顺序排列，每条消息都有一个分配给它的偏移量。Kafka不保证跨分区的消息有序，但是能够保证每个分区内的消息是有序的。

  除了增加吞吐量，分区还有另一个目的，它允许主题的消息分散在多台机器上，这样给定主题的容量就不会局限于一台服务器上的可用磁盘空间。

- 分区按键对数据进行分组

  Kafka处理键/值对格式的数据，如果键为空，那么生产者将采用轮询（round-robin）方式选择分区写入记录。如果键不为空，Kafka会使用以下公式（如下伪代码所示）确定将键/值对发送到哪个分区。通过使用确定性方法来选择分区，使得具有相同键的记录将会按序总是被发送到同一个分区。默认的分区器使用此方法，如果需要使用不同的策略选择分区，则可以提供自定义的分区器。

- 自定义分区器

  组合键分区识就需要自定义，可以使用下面配置指定一个自定义分区器

  partitioner.class=bbejeck_2.partitioner.PurchaseKeyPartitioner

- 确定恰当的分区数

  在创建主题时决定要使用的分区数既是一门艺术也是一门科学。其中一个重要的考虑因素是流入该主题的数据量。更多的数据意味着更多的分区以获得更高的吞吐量，但与生活中的任何事物一样，也要有取舍。

  增加分区数的同时也增加了TCP连接数和打开的文件句柄数。此外，消费者处理传入记录所花费的时间也会影响吞吐量。如果消费者线程有重量级处理操作，那么增加分区数可能有帮助，但是较慢的处理操作最终将会影响性能。

- 分布式日志

  当对主题进行分区时，Kafka不会将这些分区分布在一台服务上，而是将分区分散到集群中的多台服务器上。由于Kafka是在日志中追加记录，因此Kafka通过分区将这些记录分发到多台服务器上。

- 领导者、追随者

  Kafka代理有领导者（leader）和追随者（follower）的概念。在Kafka中，对每一个主题分区（topic partition），会选择其中一个代理作为其他代理（追随者）的领导者。领导者的一个主要职责是分配主题分区的副本给追随者代理服务器。

- 控制器

  Kafka使用ZooKeeper来选择代理控制器，如果代理控制器发生故障或者由于任何原因而不可用时，ZooKeeper从与领导者保持同步的一系列代理（已同步的副本[ISR]）中选出一个新的控制器。控制器的职责是为一个主题的所有分区建立领导者分区和追随者分区的关系。

- 日志管理-日志删除

  当一条新消息到达时，如果它的时间戳大于日志中第一个消息的时间戳加上log.roll.ms配置项配置的值时，Kafka就会切分日志。此时，日志被切分，一个新的日志段会被创建并作为一个活跃的日志段，而以前的活跃日志段仍然为消费者提供消息检索，日志切分有两个可选的配置项。

  log.roll.ms——这个是主配置项，但没有默认值。
  log.roll.hours——这是辅助配置项，仅当log.roll.ms没有被设置时使用，该配置项默认值是168小时。

  与日志切分一样，日志段的删除也基于消息的时间戳，而不仅是时钟时间或文件最后被修改的时间，日志段的删除基于日志中最大的时间戳。用来设置日志段删除策略的3个配置项按优先级依次列出如下，这里按优先级排列意味着排在前面的配置项会覆盖后面的配置项。

  log.retention.ms——以毫秒（ms）为单位保留日志文件的时长。
  log.retention.minutes——以分钟（min）为单位保留日志文件的时长。
  log.retention.hours——以小时（h）为单位保留日志文件。

  提出这些设置的前提是基于大容量主题的假设，这里大容量是指在一个给定的时间段内保证能够达到文件最大值。另一个配置项log.retention.bytes，可以指定较长的切分时间阈值，以控制I/O操作。最后，为了防止日志切分阈值设置得相对较大而出现日志量显著增加的情况，请使用配置项log.segment.bytes来控制单个日志段的大小。

  对于键为空的记录以及独立的记录[12]，删除日志的效果很好。但是，如果消息有键并需要预期的更新操作，那么还有一种方法更适合。

- 日志管理-日志压缩

  log.cleanup.policy=compact 根据日志的键值进行数据的更新，压缩支持按照主题配置

  删除操作会为给定键设置一个null值，作为一个墓碑标记。任何值为null的键都确保先前与其键相同的记录被去除，之后墓碑标记自身也会被去除。

- 生产者发送消息

  ```java
  Properties properties = new Properties();
  //后边可以使用一个逗号分隔的列表
  properties.put("bootstrap.servers", "localhost:9092");
  //KV序列化器
  properties.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
  properties.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
  //all:需要代理接收到所有追随者都以提交记录的确认
  //1:不等待追随者
  //0:不等待任何确认
  properties.put("acks", "1");
  //重试：如果记录的顺讯很重要，需要设置max.in.flight.requests.connect=1，以防止失败的记录在重试发送之前第二批记录成功发送
  properties.put("retries", "3");
  //数据压缩
  properties.put("compression.type", "snappy");
  //分区器类
  properties.put("partitioner.class",PurchaseKeyPartitioner.class.getName());　　
  PurchaseKey key = new PurchaseKey("12334568", new Date());
  
  try(Producer<PurchaseKey, String> producer = new KafkaProducer<>(properties)) {
     ProducerRecord<PurchaseKey, String> record = new ProducerRecord<>("transactions", key, {\"item\":\"book\",\"price\":10.99}");　　
     Callback callback = (metadata, exception) -> {
               if (exception != null) {
                  System.out.println("Encountered exception " + exception); 　　
              }
         };
      //生产者线程安全，一旦生产者将记录放到内部缓冲区，就立即返回Producer.send。缓冲区批量发送记录，具体取决于配置，如果在生产者缓冲区满时尝试发送消息，则可能会有阻塞。这里描述的Producer.send方法接受一个Callback实例，一旦领导者代理确认收到记录，生产者就会触发Callback.onComplete方法                                                                                   
      Future<RecordMetadata> sendFuture = producer.send(record, callback); 　
  }
  ```

- 指定分区

  希望所有分区收到的数据量大致相同

  ```java
  AtomicInteger partitionIndex = new AtomicInteger(0);  　　
  int currentPartition = Math.abs(partitionIndex.getAndIncrement())%numberPartitions; 
  ProducerRecord<String, String> record =  new ProducerRecord<>("topic", currentPartition, "key", "value");”
  ```

- 时间戳

  如果ProducerRecord对象设置了时间戳，那就使用这个时间戳

  如果主题设置了时间戳优先用主题的，否则使用代理级别的

  代理级别的log.message.timestamp.type配置可以被设置为CreateTime和LogAppendTime中的LogAppendTime被认为是“处理时间”，而CreateTime被认为是“事件时间。

- 消费者读取消息

  偏移量唯一标识消息，并表示消息在日志中的起始位置。消费者需要周期性地提交它们已接收到的消息的偏移量。提交一是完全处理了消息，二是发生故障或者重启时该消费者消费的起始位置。故障后消费者从何处开始消费消息取决于具体的配置。auto.offset.reset=

    - earliest从最早可用偏移量开始检索
    - latest从最新的偏移量开始检索，本质上是加入时间带你开始消费
    - none不指定重置策略，代理将会向消费者抛出异常

- 自动提交偏移量

  默认自动提交，可以通过enable.auto.commit配置，auto.commit.interval.ms与其配合使用，指定提交偏移量的频率，默认5秒。值太小增加网络流量，太大故障时会收到大量重复数据。

- 手动提交偏移量

  有同步、异步之分，无参的方法适用于所有订阅的主题和分区，带参的只会提交Map中指定的偏移量、分区和主题。使用手工提交的好处是可以直接控制记录何时被视为已处理，防止拉下来但是没实际处理完的情况。

- 创建消费者

  消费者其实是一个不断轮询的方式，通常，会在一个循环中以指定毫秒级的间隔周期性地运行消费者轮询。

- 消费者与分区

  一个消费者可以消费一到多个分区，通常是使用线程数与分区数一样的线程池，每个线程运行一个消费者。如果线程数超过分区数，超过的分区数的线程是空闲的，如果一个消费者发生故障，领导者代理将会把分配给该故障消费者的分区重新分配给另一个活跃的消费者。

  领导者代理将主题的分区分配给具有相同group.id的所有可用的消费者，group.id是一个配置项，用来标示消费者属于哪一个消费者组——这样一来，消费者就不需要位于同一台机器上。事实上，最好让消费者分散在几台机器上。这样，当一台服务器发生故障时，领导者代理可以将主题分区重新分配给一台正常运行的机器上的消费者。


- 再平衡

- 更细粒度的消费者分配

  kafak允许订阅特定主题和分区的方法

# 第3章　开发Kafka Streams

- helloworld

  接收消息并且转换为大写

# 第章 流和状态

kafka的有状态操作

流入的一条信息：日期-购买的物品-客户id-商店编号

本地状态 K-V

值转换处理器使用本地状态对流入的信息进行转换

- 带状态的转换
  （1）按客户ID检查目前累积的积分。
  （2）与当前交易的积分求和，并呈现积分总数。
  （3）将RewardAccumulator中的奖励积分总数设置为新的积分总数。
  （4）按客户ID将新的积分总数保存到本地状态存储中。”
  这里有一个问题：因为生产者没有键（除非只有一个分区），因为键没有填充，所以按轮询方式分配的话就意味着一个给定客户的交易信息不一定会分配给同一个分区。将相同客户ID的交易信息放在同一个分区很重要，因为需要根据客户ID从状态存储中查找记录。否则，会有相同客户ID的客户信息分布在不同的分区上，这样查找相同客户的信息时就需要从多个状态存储中查询。解决这个问题的方法是根据客户ID对数据重新分区，接下来我们将会介绍如何操作。


  

  

  

  

  

  

  

  

  

  

  

