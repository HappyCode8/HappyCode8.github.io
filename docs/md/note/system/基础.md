# 服务注册与发现-选择CP还是AP

>https://blog.csdn.net/qq40988670/article/details/105966202
>
>CP架构：分区异常时阻塞服务直到分区问题解决，保证一致性，常见的CP场景是对数据一致性特别敏感的业务，比如支付、HBase等分布式数据库，出现网络异常时就暂停服务，ZK也是优先保证CP的。否则银行大量取现、数据库随机返回新老数据都会有一系列问题。
>
>AP架构：数据不一致时，返回新老不同的数据，互联网常见，微博系统多地部署，微信朋友圈等，12306购票系统反复看到某车次有余票，但购买时却没有，相比CP用户体验更好
>
>```
>基于ZK的服务发现(CP)
>1. 在ZK中创建一个根路径，可以以接口命名，在这个接口下再创建调用与提供方的目录（比如providers、consumers）
>2. 提供方注册时，在提供方目录创建临时节点存储服务提供方的注册信息(临时节点是因为临时节点的生命周期与客户端会话相关，一旦机器出故障临时节点会被自动从Zookeeper删除)
>3. 订阅时，在调用目录创建一个临时节点，同时watch该服务提供方目录的所有节点
>4. 当提供方目录下有节点数据变更时，Zk通知给发起订阅的服务方
>
>问题1：
>ZK的特点是强一致性，ZK节点数据每次更新都通知其他节点同时执行更新操作，当连到ZK的节点数量特别多对ZK读写频繁且ZK存储目录达到一定数量时，ZK将不再稳定，CPU持续升高，最终宕机。宕机后，由于各业务节点还在持续发送读写请求，刚一启动就因为无法承接瞬间读写压力，马上宕机。
>
>问题2：
>ZooKeeper 无法正确处理服务发现的网络分区。在 ZooKeeper 中，无法达到仲裁数量的分区的节点客户端完全无法与ZooKeeper 及其服务发现机制进行通信。
>```
>
>```
>基于Eureka的服务发现(AP)
>1、Eureka-Client 在初始化时会将服务实例信息注册到任意一个 Eureka-Server，并且每隔 30 秒发送心跳请求。
>2、该 Eureka-Server 会将注册、心跳的请求，批量打包同步到其他 Eureka-Server。
>
>问题1：
>订阅端拿到的是服务的全量的地址：这个对于客户端的内存是一个比较大的消耗，特别在多数据中心部署的情况下，某个数据中心的订阅端往往只需要同数据中心的服务提供端即可。
>
>问题2：
>客户端采用周期性向服务端主动 pull 服务数据的模式（也就是客户端轮训的方式），这个方式存在实时性不足以及无谓的拉取性能消耗的问题。
>
>问题3：
>Eureka 集群的多副本的一致性协议采用类似“异步多写”的 AP 协议，每一个 server 都会把本地接收到的写请求发送给组成集群的其他所有的机器（Eureka 称之为 peer），特别是 hearbeat 报文是周期性持续不断的在 client->server->all peers 之间传送；这样的一致性算法，导致了如下问题
>
>- 每一台Server都需要存储全量的服务数据，Server 的内存明显会成为瓶颈。
>- 当订阅者却来越多的时候，需要扩容 Eureka 集群来提高读的能力，但是扩容的同时会导致每台 server  需要承担更多的写请求，扩容的效果不明显。
>- 组成 Eureka 集群的所有 server 都需要采用相同的物理配置，并且只能通过不断的提高配置来容纳更多的服务数据。
>
>扩展：Eureka 2.0, 为了解决上述问题而提出的，主要包含了如下的改进和增强：
>数据推送从 pull 走向 push 模式，并且实现更小粒度的服务地址按需订阅的功能。
>读写分离：写集群相对稳定，无需经常扩容；读集群可以按需扩容以提高数据推送能力。
>新增审计日志的功能和功能更丰富的 Dashboard。
>```
>
>总结
>
>对于服务发现而言，拥有可能包含虚假信息的信息要比根本不拥有任何信息更好，所以个人认为 AP 优于 CP。在 AP 模式下，如果请求到不准确的服务实例信息，导致请求发送到一个宕机的服务端，只要做好失败重试机制和负载均衡，这次请求能够顺利的进行。

# 分布式事务

## 柔性事务与刚性事务

- 刚性事务满足足CAP的CP理论，注意C是强一致性
- 柔性事务不要求强一致性，而是要求最终一致性，允许有中间状态，也就是Base理论，换句话说，就是AP状态。

## 刚性事务的解决方案

**XA规范**：XA是数据库的分布式事务，强一致性，在整个过程中，数据一张锁住状态，即从prepare到commit、rollback的整个过程中，TM（事务管理器）一直把持折数据库的锁，如果有其他人要修改数据库的该条数据，就必须等待锁的释放，存在长事务风险。XA必须要拿到所有数据源，而且数据源还要支持XA协议。目前MySQL中只有InnoDB存储引擎支持XA协议。

**XA的具体实现**：

2PC:标准XA模型

>阶段一：提交事务请求
>
>```
>1. 事务询问。协调者向所有参与者发送事务内容，询问是否可以执行提交操作，并开始等待各参与者进行响应；
>2. 执行事务。各参与者节点，执行事务操作，并将Undo和Redo操作计入本机事务日志；
>3. 各参与者向协调者反馈事务问询的响应。成功执行返回Yes，否则返回No。
>```
>
>阶段二：执行事务提交;
>
>```
>协调者在阶段二决定是否最终执行事务提交操作。这一阶段包含两种情形：
>
>执行事务提交
>所有参与者reply Yes，那么执行事务提交。
>
>1. 发送提交请求。协调者向所有参与者发送Commit请求；
>2. 事务提交。参与者收到Commit请求后，会正式执行事务提交操作，并在完成提交操作之后，释放在整个事务执行期间占用的资源；
>3. 反馈事务提交结果。参与者在完成事务提交后，写协调者发送Ack消息确认；
>4. 完成事务。协调者在收到所有参与者的Ack后，完成事务。
>
>中断事务
>事情总会出现意外，当存在某一参与者向协调者发送No响应，或者等待超时。协调者只要无法收到所有参与者的Yes响应，就会中断事务。
>
>1. 发送回滚请求。协调者向所有参与者发送Rollback请求；
>2. 回滚。参与者收到请求后，利用本机Undo信息，执行Rollback操作。并在回滚结束后释放该事务所占用的系统资源；
>3. 反馈回滚结果。参与者在完成回滚操作后，向协调者发送Ack消息；
>4. 中断事务。协调者收到所有参与者的回滚Ack消息后，完成事务中断。
>```
>
>2PC缺点：
>
>- 性能问题
>- 协调者单点故障问题
>- 网络导致的数据不一致的问题

3PC: 对2PC的改进 

> 阶段一：CanCommit
>
> ```
> 1. 事务询问。协调者向所有参与者发送包含事务内容的canCommit的请求，询问是否可以执行事务提交，并等待应答；
> 2. 各参与者反馈事务询问。正常情况下，如果参与者认为可以顺利执行事务，则返回Yes，否则返回No。
> ```
>
> 阶段二：PreCommit
>
> ```
> 在本阶段，协调者会根据上一阶段的反馈情况来决定是否可以执行事务的PreCommit操作。有以下两种可能：
> 
> 执行事务预提交
> 
> 1. 发送预提交请求。协调者向所有节点发出PreCommit请求，并进入prepared阶段；
> 2. 事务预提交。参与者收到PreCommit请求后，会执行事务操作，并将Undo和Redo日志写入本机事务日志；
> 3. 各参与者成功执行事务操作，同时将反馈以Ack响应形式发送给协调者，同事等待最终的Commit或Abort指令。
> 
> 中断事务
> 加入任意一个参与者向协调者发送No响应，或者等待超时，协调者在没有得到所有参与者响应时，即可以中断事务：
> 
> 1. 发送中断请求。 协调者向所有参与者发送Abort请求；
> 2. 中断事务。无论是收到协调者的Abort请求，还是等待协调者请求过程中出现超时，参与者都会中断事务；
> ```
>
> 阶段三：doCommit
>
> ```
> 在这个阶段，会真正的进行事务提交，同样存在两种可能。
> 
> 执行提交
> 1. 发送提交请求。假如协调者收到了所有参与者的Ack响应，那么将从预提交转换到提交状态，并向所有参与者，发送doCommit请求；
> 2. 事务提交。参与者收到doCommit请求后，会正式执行事务提交操作，并在完成提交操作后释放占用资源；
> 3. 反馈事务提交结果。参与者将在完成事务提交后，向协调者发送Ack消息；
> 4. 完成事务。协调者接收到所有参与者的Ack消息后，完成事务。
> 
> 中断事务
> 在该阶段，假设正常状态的协调者接收到任一个参与者发送的No响应，或在超时时间内，仍旧没收到反馈消息，就会中断事务：
> 
> 1. 发送中断请求。协调者向所有的参与者发送abort请求；
> 2. 事务回滚。参与者收到abort请求后，会利用阶段二中的Undo消息执行事务回滚，并在完成回滚后释放占用资源；
> 3. 反馈事务回滚结果。参与者在完成回滚后向协调者发送Ack消息；
> 4. 中端事务。协调者接收到所有参与者反馈的Ack消息后，完成事务中断。
> ```

**2PC和3PC的区别：**

三阶段提交协议在协调者和参与者中都引入 **超时机制**，并且把两阶段提交协议的第一个阶段拆分成了两步：询问，然后再锁资源，最后真正提交。三阶段提交的三个阶段分别为：can_commit，pre_commit，do_commit



## 可靠消息最终一致性

1. 什么是可靠消息最终一致性事务？

> 可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方(消息消费者)一定能够接收消息并处理事务成功，此方案强调的是**只要消息发给事务参与方最终事务要达到一致**。

2. 怎么实现？

   >利用消息中间件完成。

3. 有哪些问题？

   >- 本地事务与消息原子性的问题
   >
   >  事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息。即实现本地事务和消息发送的原子性，要么都成功，要么都失败。本地事务与消息发送的原子性问题是实现可靠消息最终一致性方案的关键问题。
   >
   >方案一：
   >
   >```
   >begin transaction；
   >    //1.发送MQ
   >    //2.数据库操作
   >commit transation;
   >```
   >
   >这种情况下无法保证数据库操作与发送消息的一致性，因为可能发送消息成功，数据库操作失败。
   >
   >方案二：
   >
   >```
   >begin transaction；
   >    //1.数据库操作
   >    //2.发送MQ
   >commit transation;
   >```
   >
   >这种情况下貌似没有问题，如果发送MQ消息失败，就会抛出异常，导致数据库事务回滚。但如果是超时异常（MQ发送但是确认超时），数据库回滚，但MQ其实已经正常发送了，同样会导致不一致。
   >
   >- 事务参与方接收消息的可靠性
   >
   >  事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息。
   >
   >- 消息重复消费的问题
   >
   >  若某一个消费节点超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重复消费。

4. 怎么解决这些问题？

   >- 本地消息表方案
   >
   >  通过本地事务保证数据业务操作和消息的一致性，然后通过定时任务将消息发送至消息中间件，待确认消息发送给消费方成功再将消息删除。下面以注册送积分为例来说明：
   >
   >  共有两个微服务，用户服务和积分服务，用户服务负责添加用户，积分服务负责增加积分：
   >
   >  ![积分图](https://s2.loli.net/2022/03/26/T1jrKWOcUfH6gIL.png)
   >
   >  交互流程如下：
   >
   >  1. 用户注册
   >
   >     用户服务在本地事务新增用户和增加 ”积分消息日志“。（用户表和消息表通过本地事务保证一致）
   >
   >     下边是伪代码
   >
   >     ```
   >     begin transaction；
   >         //1.新增用户
   >         //2.存储积分消息日志
   >     commit transation;
   >     ```
   >
   >     这种情况下，本地数据库操作与存储积分消息日志处于同一个事务中，本地数据库操作与记录消息日志操作具备原子性。
   >
   >  2. 定时任务扫描日志
   >
   >     **如何保证将消息发送给消息队列呢**
   >
   >     经过第一步消息已经写到消息日志表中，可以启动独立的线程，定时对消息日志表中的消息进行扫描并发送至消息中间件，在消息中间件反馈发送成功后删除该消息日志，否则等待定时任务下一周期重试。
   >
   >  3. 消费消息
   >
   >     **如何保证消费者一定能消费到消息呢？**
   >
   >     　　这里可以使用MQ的ack（即消息确认）机制，消费者监听MQ，如果消费者接收到消息并且业务处理完成后向MQ发送ack（即消息确认），此时说明消费者正常消费消息完成，MQ将不再向消费者推送消息，否则消费者会不断重试向消费者来发送消息。积分服务接收到”增加积分“消息，开始增加积分，积分增加成功后向消息中间件回应ack，否则消息中间件将重复投递此消息。
   >
   >     **由于消息会重复投递，积分服务的”增加积分“功能需要实现幂等性。**
   >
   >- RocketMQ事务消息方案
   >
   >  仍然以注册送积分为例
   >
   >  1. 用户服务发送增加积分事务消息，MQ Server将消息状态标记为Prepared（预备状态），注意此时这条消息消费者（积分服务）是无法消费到的。
   >  2. 接收到MQ的成功消息后，用户服务提交本地事务添加用户
   >  3. 如果添加成功，像MQ发送commit消息，MQ接到消息后将”增加积分消息“ 状态标记为可消费，此时积分服务正常消费消息；添加失败像MQ发送回滚消息，删除增加积分消息
   >  4. 积分服务消费消息，消费成功则向MQ回应ack，否则将重复接收消息。这里ack默认自动回应，即程序执行正常则自动回应ack。
   >  5. 如果执行Producer端本地事务过程中，执行端挂掉，或者超时，MQ Server将会不停的询问同组的其他 Producer 来获取事务执行状态，这个过程叫事务回查。MQ Server会根据事务回查结果来决定是否投递消息。

5. 基于以上理论实现转账交易

   >背景：A银行的李三给B银行的李四转钱
   >
   >方案：A行扣钱并通过消息队列通知B行
   >
   >AB行库表一样
   >
   >```sql
   >CREATE TABLE `account_info`    (
   >    `id` bigint(20) NOT NULL AUTO_INCREMENT,
   >    `account_name` varchar(100) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT '户主姓名',
   >    `account_no` varchar(100) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT '银行卡号',
   >    `account_password` varchar(100) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT '帐户密码',
   >    `account_balance` double NULL DEFAULT NULL COMMENT '帐户余额', PRIMARY KEY (`id`) USING BTREE
   >)    ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8 COLLATE = utf8_bin ROW_FORMAT = Dynamic;
   >```
   >
   >两行还分别有一个交易记录表用于去重
   >
   >```sql
   >CREATE TABLE `de_duplication`    (
   >    `tx_no`    varchar(64) COLLATE utf8_bin NOT NULL,
   >    `create_time` datetime(0) NULL DEFAULT NULL,
   >    PRIMARY KEY (`tx_no`) USING BTREE
   >) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_bin ROW_FORMAT = Dynamic;
   >```
   >
   >A行代码
   >
   >Dao
   >
   >```java
   >@Mapper
   >@Component
   >public interface AccountInfoDao {
   >
   >    @Update("update account_info set account_balance=account_balance+#{amount} where account_no=# {accountNo}")//更新账户金额
   >    int updateAccountBalance(@Param("accountNo") String accountNo, @Param("amount") Double amount);
   >
   >    @Select("select count(1) from de_duplication where tx_no = #{txNo}")
   >    int isExistTx(String txNo);//查询交易记录表
   >
   >    @Insert("insert into de_duplication values(#{txNo},now());")
   >    int addTx(String txNo);//插入交易记录表
   >}
   >```
   >
   >Service
   >
   >```java
   >@Service
   >@Slf4j
   >public class AccountInfoServiceImpl implements AccountInfoService {
   >    @Resource
   >    private RocketMQTemplate rocketMQTemplate;
   >    
   >    @Autowired
   >    private AccountInfoDao accountInfoDao;
   >
   >    /**
   >    *    更新帐号余额‐发送消息
   >    *    producer向MQ Server发送消息
   >    *    
   >    *    @param accountChangeEvent
   >    */
   >    @Override
   >    public void sendUpdateAccountBalance(AccountChangeEvent accountChangeEvent) { //构建消息体
   >        JSONObject jsonObject = new JSONObject(); 
   >        jsonObject.put("accountChange",accountChangeEvent); 
   >        Message<String> message =MessageBuilder.withPayload(jsonObject.toJSONString()).build(); 
   >        TransactionSendResult sendResult =rocketMQTemplate.sendMessageInTransaction("producer_group_txmsg_bank1", "topic_txmsg", message, null);
   >        log.info("send transcation message body={},result= {}",message.getPayload(),sendResult.getSendStatus());
   >    }
   >
   >    /**
   >    *    更新帐号余额‐本地事务
   >    *    producer发送消息完成后接收到MQ Server的回应即开始执行本地事务
   >    *
   >    *    @param accountChangeEvent
   >    */
   >    @Transactional
   >    @Override
   >    public void doUpdateAccountBalance(AccountChangeEvent accountChangeEvent) { log.info("开始更新本地事务，事务号：{}",accountChangeEvent.getTxNo());
   >        accountInfoDao.updateAccountBalance(accountChangeEvent.getAccountNo(),accountChangeEvent.getAmount() * ‐1);
   >        //为幂等作准备
   >        accountInfoDao.addTx(accountChangeEvent.getTxNo()); 
   >        if(accountChangeEvent.getAmount() == 2){
   >            throw new RuntimeException("bank1更新本地事务时抛出异常");
   >        }
   >        log.info("结束更新本地事务，事务号：{}",accountChangeEvent.getTxNo());
   >    }
   >}
   >```
   >
   >RocketMQLocalTransactionListener
   >
   >```java
   >@Component
   >@Slf4j
   >@RocketMQTransactionListener(txProducerGroup = "producer_group_txmsg_bank1") 
   >public class ProducerTxmsgListener implements RocketMQLocalTransactionListener {
   >
   >    @Autowired
   >    AccountInfoService accountInfoService;
   >
   >    @Autowired
   >    AccountInfoDao accountInfoDao;
   >
   >    //prepare消息发送成功回调此方法，此方法执行本地事务
   >    @Override
   >    @Transactional
   >    public RocketMQLocalTransactionState executeLocalTransaction(Message message, Object arg) { 
   >    //解析消息内容
   >    try {
   >            String jsonString = new String((byte[]) message.getPayload()); 
   >            JSONObject jsonObject = JSONObject.parseObject(jsonString); 
   >            AccountChangeEvent accountChangeEvent =JSONObject.parseObject(jsonObject.getString("accountChange"), AccountChangeEvent.class);
   >            //扣除金额
   >            accountInfoService.doUpdateAccountBalance(accountChangeEvent);
   >      //执行成功后确认消息让B行看到
   >            return RocketMQLocalTransactionState.COMMIT;
   >        } catch (Exception e) { 
   >            log.error("executeLocalTransaction 事务执行失败",e); 
   >            e.printStackTrace();
   >      //不成功则回滚
   >            return RocketMQLocalTransactionState.ROLLBACK;
   >        }
   >    }
   >
   >    //此方法检查事务执行状态，避免执行本地事务时机器挂掉
   >    @Override
   >    public RocketMQLocalTransactionState checkLocalTransaction(Message message) { 
   >        RocketMQLocalTransactionState state;
   >        final JSONObject jsonObject = JSON.parseObject(new String((byte[])
   >        message.getPayload()));
   >        AccountChangeEvent accountChangeEvent =JSONObject.parseObject(jsonObject.getString("accountChange"),AccountChangeEvent.class);
   >        //事务id
   >        String txNo = accountChangeEvent.getTxNo();
   >        int isexistTx = accountInfoDao.isExistTx(txNo);
   >        log.info("回查事务，事务号: {} 结果: {}", accountChangeEvent.getTxNo(),isexistTx); 
   >        if(isexistTx>0){
   >            state= RocketMQLocalTransactionState.COMMIT; 
   >        }else{
   >            state=    RocketMQLocalTransactionState.UNKNOWN;
   >        }
   >        return state;
   >    }
   >}
   >```
   >
   >Controller
   >
   >```java
   >@RestController
   >@Slf4j
   >public class AccountInfoController {
   >
   >    @Autowired
   >    private AccountInfoService accountInfoService;
   >
   >    @GetMapping(value = "/transfer")
   >    public String transfer(@RequestParam("accountNo")String accountNo,@RequestParam("amount") Double amount){
   >        String tx_no = UUID.randomUUID().toString();//转账前生成唯一订单号
   >        AccountChangeEvent accountChangeEvent = new AccountChangeEvent(accountNo,amount,tx_no);
   >        accountInfoService.sendUpdateAccountBalance(accountChangeEvent); return "转账成功";
   >    }
   >}
   >```
   >
   >
   >
   >B行代码
   >
   >Service
   >
   >```java
   >@Service
   >@Slf4j
   >public class AccountInfoServiceImpl implements AccountInfoService {
   >
   >    @Autowired
   >    AccountInfoDao accountInfoDao;
   >
   >
   >    /**
   >    *    消费消息，更新本地事务，添加金额
   >    *    @param accountChangeEvent
   >    */
   >    @Override
   >    @Transactional
   >    public void addAccountInfoBalance(AccountChangeEvent accountChangeEvent) { 
   >        log.info("bank2更新本地账号，账号：{},金额：{}",accountChangeEvent.getAccountNo(),accountChangeEvent.getAmount());
   >        //幂等校验
   >        int existTx = accountInfoDao.isExistTx(accountChangeEvent.getTxNo()); 
   >        if(existTx<=0){
   >            //执行更新
   >          accountInfoDao.updateAccountBalance(accountChangeEvent.getAccountNo(),accountChangeEvent.getAmoun t());
   >            //添加事务记录
   >            accountInfoDao.addTx(accountChangeEvent.getTxNo());
   >            log.info("更新本地事务执行成功，本次事务号: {}", accountChangeEvent.getTxNo()); }else{
   >            log.info("更新本地事务执行失败，本次事务号: {}", accountChangeEvent.getTxNo());
   >        }
   >    }
   >}
   >```
   >
   >MQ监听
   >
   >```java
   >@Component
   >@RocketMQMessageListener(topic = "topic_txmsg",consumerGroup = "consumer_txmsg_group_bank2") 
   >@Slf4j
   >public class TxmsgConsumer implements RocketMQListener<String> { 
   >    @Autowired
   >    AccountInfoService accountInfoService;
   >
   >    @Override
   >    public void onMessage(String s) {
   >        log.info("开始消费消息:{}",s);
   >        //解析消息为对象
   >        final JSONObject jsonObject = JSON.parseObject(s); 
   >        AccountChangeEvent accountChangeEvent =JSONObject.parseObject(jsonObject.getString("accountChange"),AccountChangeEvent.class);
   >        //调用service增加账号金额
   >        accountChangeEvent.setAccountNo("2");
   >        accountInfoService.addAccountInfoBalance(accountChangeEvent);
   >    }
   >}
   >```
   >
   >测试：
   >
   >bank1本地事务失败，则bank1不发送转账消息。
   >
   > bank2接收转账消息失败，会进行重试发送消息。
   >
   > bank2多次消费同一个消息，实现幂等。

6. 总结

   可靠消息最终一致性就是保证消息从生产方经过消息中间件传递到消费方的一致性，本案例使用了RocketMQ作为消息中间件，RocketMQ主要解决了两个功能：

   - 本地事务与消息发送的原子性问题。
   - 事务参与方接收消息的可靠性。

   可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。

## 补偿型事务

可靠性消息最终一致性有一个问题，就是李四账户转账如果除了问题，那么怎么解决？答案是进行补偿型事务。

1. 补偿型事务流程

   >正常成功流程
   >
   >- A行扣减但是暂时不提交
   >- 远程调用B行服务
   >- 成功后A行才提交
   >
   >异常时额外发送远程调用到现金服务以加上之前扣掉的金额

## 尽最大努力通知

**最大努力通知事务**主要用于**外部系统**，因为外部的网络环境更加复杂和不可信，所以只能尽最大努力去通知实现数据最终一致性，**比如充值平台与运营商、支付对接、商户通知等等跨平台、跨企业的系统间业务交互场景**；

# 一些系统设计思路

> 微博点赞系统设计思路：https://mp.weixin.qq.com/s/GwCkm-Ba_7NuZFFCQBnD3g
>
> redis实现的点赞：https://mp.weixin.qq.com/s/fDOmWWNKHBOWx6ITcsAZeQ



# 接口幂等性

- insert前先select，如果数据已存在就执行update

- 加悲观锁

  ```sql
  update user amount = amount-100 where id=123;
  #多次相同的请求，可能会导致用户A的余额变成负数。这种情况，用户A来可能要哭了
  
  #通常情况下通过如下sql锁住单行数据
  select * from user id=123 for update;
  ```

  悲观锁需要在同一个事务操作过程中锁住一行数据，如果事务耗时比较长，会造成大量的请求等待，影响接口性能。此外，每次请求接口很难保证都有相同的返回值，所以不适合幂等性设计场景，但是在防重场景中是可以的使用的。

  >需要特别注意的是：如果使用的是mysql数据库，存储引擎必须用innodb，因为它才支持事务。此外，这里id字段一定要是主键或者唯一索引，不然会锁住整张表。

  > 防重设计主要为了避免产生重复数据，对接口返回没有太多要求。而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。

- 加乐观锁

  ``` sql
  # 将id,verison作为条件
  select id,amount,version from user id=123;
  # 第一次更新成功
  update user set amount=amount+100,version=version+1
  where id=123 and version=1;
  # 第二次更新不成功
  update user set amount=amount+100,version=version+1
  where id=123 and version=1;
  ```

- 加唯一索引

- 建防重表

  有时候表中并非所有的场景都不允许产生重复的数据，只有某些特定场景才不允许。这时候，直接在表中加唯一索引，显然是不太合适的。

  针对这种情况，我们可以通过`建防重表`来解决问题。

  该表可以只包含两个字段：`id` 和 `唯一索引`，唯一索引可以是多个字段比如：name、code等组合起来的唯一标识

  >需要特别注意的是：防重表和业务表必须在同一个数据库中，并且操作要在同一个事务中。

- 状态机

  很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态。如果这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。

  >主要特别注意的是，该方案仅限于要更新的`表有状态字段`，并且刚好要更新`状态字段`的这种特殊情况，并非所有场景都适用。

- 分布式锁

  `redis`或zookeeper

  目前主要有三种方式实现redis的分布式锁：

  1. setNx命令
  2. set命令
  3. Redission框架

- 获取token

  需要两次请求才能完成一次业务操作。

  1. 第一次请求获取`token`
  2. 第二次请求带着这个`token`，完成业务操作。

# 优化性能常见手段

- 中间件较多时，优化网络通信质量。
- 数据库查询耗时时，需要对查询进行优化，比如添加索引。
- 模板的渲染速度，可以通过设置模板缓存。
- 静态资源的获取，可以通过 Nginx 动静分离来解决。（下期再讲）
- 日志太多，需要减少不必要的打 log 操作。

# 数据压缩

HashMap<Integer, V>   ->  IntObjectHashMap<V>

Set<Integer> -> intSet

IntObjectHashMap，这个类出自 Netty，根据https://www.bilibili.com/video/BV1eX4y1F7zJ?p=2的测算，存入10000个数据，开销降低40%-60%

IntSet节省80%，不生成Integer对象，GC性能更好

- IntObjectHashMap对key冲突时使用的是开放寻址策略中的线性探测
- 它的key限制了就是int类型的值，所以初始化时不能指定key的类型
- 它内部有key[],value[]两个数组

HashMap的结构是 Node[] table; Node 下面有Hash，Key，Value，Next四个属性。
而IntObjectHashMap的结构是int[] keys 和 Object[] values.
在插入时，同样把int先取模落桶，如果遇到冲突，则不采样HashMap的链地址法，而是用开放地址法（线性探测法）index＋1找下一个空桶，最后在keys[index]，values[index]中分别记录。在查找时也是先落桶，然后在key[index++]中逐个比较key。
所以，对比整个数据结构，省的不止是int vs Integer，还有每个Node的内容。
而性能嘛，IntObjectHashMap还是稳赢一点的，随便测了几种场景，耗时至少都有24ms vs 28ms的样子，好的时候甚至快1/3。

# CQRS

Command Query Responsibility Segregation（命令查询职责隔离）

例如电商系统，包含订单、用户、商品等等数据，数据的变更操作、查询操作，都是基于这一套数据模型的。但是，实际场景下的查询需求是多种多样。例如这3类人群：

- 商家
- 买家用户
- 电商运营人员

他们的数据视角是不同的，各自的关注角度不同，需要查询的数据就完全不同，但数据模型是一套啊，怎么办？是不是就需要做数据关联、构建临时数据集合等等复杂的操作啊，基于一种数据模型，来实现 N 种视角的查询，既别扭又麻烦。

- CQRS 把数据的变更和查询拆开了，有各自的数据模型。

- 命令模型负责数据的变更，并把最新数据同步给查询模型。

- 查询模型根据自己的想法来安排数据，想怎么用就怎么用。

- 好处是可以让查询更加自由，更快的满足多变的业务需求。

- 坏处是增加了架构的复杂度，还有数据同步带来的问题。

# 如何搞垮一个系统

一、系统单点

二、程序中多用循环


三、系统间增加依赖

四、不做服务补偿

五、不做幂等设计

六、不设置超时

七、不控制流量

八、不做监控预警

九、没有重试策略

十、不做系统隔离

十一、代码同步调用

十二、不做热数据缓存

十三、不做系统分级

十四、没有服务降级


十五、无灰度和回滚方案

十六、程序多做远程调用

十七、不做熔断机制

十八、不做代码扫描

十九、不做线上压测
原文链接：https://blog.csdn.net/yellowzf3/article/details/115713526

# JJWT

一个JWT**(java web token)**由三部分组成

- Header(头部)——base64编码当然Json字符串，里边说明类型和使用的算法
- Payload(载荷)——base64编码的Json字符串，里边存放有效信息
- Signature(签名)——使用指定算法，通过Header和Payload加盐计算的字符串

各部分以”.“分隔，例如

`eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ3eWoiLCJleHAiOjE2MDI0MTU0NTUsImlhdCI6MTYwMjQxMzY1NX0.gNZZdUztdC9qwzInC_wyYA5dGbAHps6i2yy_5_7IVE4`

直接通过base64解码即可获得[base64在线加解密](https://tool.oschina.net/encrypt?type=3)，上述JWT的Header和Payload分别为

` {"alg":"HS256"}{"sub":"wyj","exp":1602415455,"iat":1602413655}`

请求的时候在HTTP的headers参数里面的authorization里边，值的前面加`Bearer`关键字和空格，除此之外也可以在url和request body中传递

## Header

如上所示，Header里主要说明类型和使用算法

## Payload

### 标准中注册的声明

- iss： jwt签发者
- sub: jwt所面向的用户
- aud: 接收jwt的一方
- exp: jwt的过期时间，这个过期时间必须要大于签发时间
- nbf: 定义在什么时间之前，该jwt都是不可用的.
- iat: jwt的签发时间
- jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击

### 公共的声明

可以添加任何信息，但不建议添加敏感信息

### 私有的声明

私有声明是提供者和消费者所共同定义的声明

## Signature

```java
encodedString = base64UrlEncode(header) + '.' + base64UrlEncode(payload);
signature = HMACSHA256(encodedString, 'secret');
```

其中的**’secret‘**是服务端的私钥，需要严格保密，如果客户端获得了这个秘钥，那就可以自己签发token了。**服务端主要通过第三部分来确认这个token确实是服务端签发的，因为只有服务端能通过秘钥根据Header与Payload验证重新加密对比签名**。

## 签名算法

HS256:对称签名

RS256:非对称签名

## 一致性哈希

利用哈希去缓存

- 问题？

我们希望有同样ID的请求打到同样的机器上，这可能是因为那台机器有对应的缓存，也可能是因为那台机器上有上下文只有那台机器才能处理

- 怎么办？

将ID做哈希，哈希到不同机器

- 有一台机器崩了还能用吗？

不行了，10台机器，原本ID14的取模到4，4号机器崩了，5-10号顺序往前进一位，ID14号打到了原本的5号机器上，

而且大于4号的都不行了，这会引发大规模报错、大规模缓存雪崩

- 那我不对服务器数取模，对一个固定的数字取模不行吗？

那咋扩容、缩容，而且原来模4的请求不是都不能用吗

- 那把10台机器分布到一个2^32-1的哈希环上，用IP什么的对2^32-1进行取模，分布上去，我再用ID取模也放到哈希环上，然后顺时针找最近的机器搞上去，所有请求都这么搞，当一台机器挂了的时候，原本应该到这台的请求到了顺时针下一台，其余的不受影响，这样可以吗？

可以是可以，但是你就10台机器，对2^32取模以后差不多集中在环上的一个部分，但是请求ID有123456781234567123456这么长，一取模，大部分估计都落到了一台上，那台机器要是挂了，咋办?

<img src="./images/image-20210724162702288.png" alt="image-20210724162702288" style="zoom:25%;" />

- 那把那10台服务器弄点虚拟节点出来，放在哈希环的空白处，每个虚拟他个100000台，均匀撒在环上的空白处能行吗？

这样倒是可以，咋虚拟？

- [.........NodeA1............NodeA2...............NodeA3.............]顺时针找，碰到带序号的都给映射回不带序号的节点去



# 面试

秒杀

https://mp.weixin.qq.com/s/l05_28xe6O4vZUQEmnu2Ug

## 15分钟未支付自动取消订单？

- 方案1

  每隔n分钟搜索订单时间大于15分钟未支付的订单状态改为取消，单机使用springtask、集群使用分布式任务调度。

  优点：简单

  缺点：n分钟扫描一次订单状态不能及时更新，n秒的话订单表查询压力大

- 方案二

  redis6的客户端缓存监听方案，监听redis6数据变化。创建订单时额外缓存到redis，放入set类型（key为订单编号，value为实例id，超时时间15分钟），超时时取消，完成时移除缓存

  优点：及时有效，集群友好（哪个实例创建哪个实例取消）

  缺点：基于长连接，连接重启后客户端缓存监听机制会失效，需要手动补偿；实例数量变化以后需要重新做分配；需要升级redis6

- 方案三

  延迟消息，死信队列，在15分钟内没有被消费就送到死信队列，由死信队列处理

  优点：消息及时投递，集群友好，代码量小，不需要额外集群调度，也不绑定具体实例

  缺点：需要额外关注幂等性等MQ自身引起的问题

