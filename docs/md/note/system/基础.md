# 服务注册与发现-选CP还是AP

> [原文](https://blog.csdn.net/qq40988670/article/details/105966202)
> 
> CP架构：分区异常时阻塞服务直到分区问题解决，保证一致性，常见的CP场景是对数据一致性特别敏感的业务，比如支付、HBase等分布式数据库，出现网络异常时就暂停服务，ZK也是优先保证CP的。否则银行大量取现、数据库随机返回新老数据都会有一系列问题。
> 
> AP架构：数据不一致时，返回新老不同的数据，互联网常见，微博系统多地部署，微信朋友圈等，12306购票系统反复看到某车次有余票，但购买时却没有，相比CP用户体验更好
> 
> ```
> 基于ZK的服务发现(CP)
> 1. 在ZK中创建一个根路径，可以以接口命名，在这个接口下再创建调用与提供方的目录（比如providers、consumers）
> 2. 提供方注册时，在提供方目录创建临时节点存储服务提供方的注册信息(临时节点是因为临时节点的生命周期与客户端会话相关，一旦机器出故障临时节点会被自动从Zookeeper删除)
> 3. 订阅时，在调用目录创建一个临时节点，同时watch该服务提供方目录的所有节点
> 4. 当提供方目录下有节点数据变更时，Zk通知给发起订阅的服务方
> 
> 问题1：
> ZK的特点是强一致性，ZK节点数据每次更新都通知其他节点同时执行更新操作，当连到ZK的节点数量特别多对ZK读写频繁且ZK存储目录达到一定数量时，ZK将不再稳定，CPU持续升高，最终宕机。宕机后，由于各业务节点还在持续发送读写请求，刚一启动就因为无法承接瞬间读写压力，马上宕机。
> 
> 问题2：
> ZooKeeper 无法正确处理服务发现的网络分区。在 ZooKeeper 中，无法达到仲裁数量的分区的节点客户端完全无法与ZooKeeper 及其服务发现机制进行通信。
> ```
> 
> ```
> 基于Eureka的服务发现(AP)
> 1、Eureka-Client 在初始化时会将服务实例信息注册到任意一个 Eureka-Server，并且每隔 30 秒发送心跳请求。
> 2、该 Eureka-Server 会将注册、心跳的请求，批量打包同步到其他 Eureka-Server。
> 
> 问题1：
> 订阅端拿到的是服务的全量的地址：这个对于客户端的内存是一个比较大的消耗，特别在多数据中心部署的情况下，某个数据中心的订阅端往往只需要同数据中心的服务提供端即可。
> 
> 问题2：
> 客户端采用周期性向服务端主动 pull 服务数据的模式（也就是客户端轮训的方式），这个方式存在实时性不足以及无谓的拉取性能消耗的问题。
> 
> 问题3：
> Eureka 集群的多副本的一致性协议采用类似“异步多写”的 AP 协议，每一个 server 都会把本地接收到的写请求发送给组成集群的其他所有的机器（Eureka 称之为 peer），特别是 hearbeat 报文是周期性持续不断的在 client->server->all peers 之间传送；这样的一致性算法，导致了如下问题
> 
> - 每一台Server都需要存储全量的服务数据，Server 的内存明显会成为瓶颈。
> - 当订阅者却来越多的时候，需要扩容 Eureka 集群来提高读的能力，但是扩容的同时会导致每台 server  需要承担更多的写请求，扩容的效果不明显。
> - 组成 Eureka 集群的所有 server 都需要采用相同的物理配置，并且只能通过不断的提高配置来容纳更多的服务数据。
> 
> 扩展：Eureka 2.0, 为了解决上述问题而提出的，主要包含了如下的改进和增强：
> 数据推送从 pull 走向 push 模式，并且实现更小粒度的服务地址按需订阅的功能。
> 读写分离：写集群相对稳定，无需经常扩容；读集群可以按需扩容以提高数据推送能力。
> 新增审计日志的功能和功能更丰富的 Dashboard。
> ```
> 
> 总结
> 
> 对于服务发现而言，拥有可能包含虚假信息的信息要比根本不拥有任何信息更好，所以个人认为 AP 优于 CP。在 AP 模式下，如果请求到不准确的服务实例信息，导致请求发送到一个宕机的服务端，只要做好失败重试机制和负载均衡，这次请求能够顺利的进行。

# 分布式事务

## 柔性事务与刚性事务

- 刚性事务满足足CAP的CP理论，注意C是强一致性
- 柔性事务不要求强一致性，而是要求最终一致性，允许有中间状态，也就是Base理论，换句话说，就是AP状态。

## 刚性事务的解决方案

**XA规范**：XA是数据库的分布式事务，强一致性，在整个过程中，数据一张锁住状态，即从prepare到commit、rollback的整个过程中，TM（事务管理器）一直把持折数据库的锁，如果有其他人要修改数据库的该条数据，就必须等待锁的释放，存在长事务风险。XA必须要拿到所有数据源，而且数据源还要支持XA协议。目前MySQL中只有InnoDB存储引擎支持XA协议。

**XA的具体实现**：

2PC:标准XA模型

> 阶段一：提交事务请求
> 
> ```
> 1. 事务询问。协调者向所有参与者发送事务内容，询问是否可以执行提交操作，并开始等待各参与者进行响应；
> 2. 执行事务。各参与者节点，执行事务操作，并将Undo和Redo操作计入本机事务日志；
> 3. 各参与者向协调者反馈事务问询的响应。成功执行返回Yes，否则返回No。
> ```
> 
> 阶段二：执行事务提交;
> 
> ```
> 协调者在阶段二决定是否最终执行事务提交操作。这一阶段包含两种情形：
> 
> 执行事务提交
> 所有参与者reply Yes，那么执行事务提交。
> 
> 1. 发送提交请求。协调者向所有参与者发送Commit请求；
> 2. 事务提交。参与者收到Commit请求后，会正式执行事务提交操作，并在完成提交操作之后，释放在整个事务执行期间占用的资源；
> 3. 反馈事务提交结果。参与者在完成事务提交后，写协调者发送Ack消息确认；
> 4. 完成事务。协调者在收到所有参与者的Ack后，完成事务。
> 
> 中断事务
> 事情总会出现意外，当存在某一参与者向协调者发送No响应，或者等待超时。协调者只要无法收到所有参与者的Yes响应，就会中断事务。
> 
> 1. 发送回滚请求。协调者向所有参与者发送Rollback请求；
> 2. 回滚。参与者收到请求后，利用本机Undo信息，执行Rollback操作。并在回滚结束后释放该事务所占用的系统资源；
> 3. 反馈回滚结果。参与者在完成回滚操作后，向协调者发送Ack消息；
> 4. 中断事务。协调者收到所有参与者的回滚Ack消息后，完成事务中断。
> ```
> 
> 2PC缺点：
> 
> - 性能问题
> - 协调者单点故障问题
> - 网络导致的数据不一致的问题

3PC: 对2PC的改进 

> 阶段一：CanCommit
> 
> ```
> 1. 事务询问。协调者向所有参与者发送包含事务内容的canCommit的请求，询问是否可以执行事务提交，并等待应答；
> 2. 各参与者反馈事务询问。正常情况下，如果参与者认为可以顺利执行事务，则返回Yes，否则返回No。
> ```
> 
> 阶段二：PreCommit
> 
> ```
> 在本阶段，协调者会根据上一阶段的反馈情况来决定是否可以执行事务的PreCommit操作。有以下两种可能：
> 
> 执行事务预提交
> 
> 1. 发送预提交请求。协调者向所有节点发出PreCommit请求，并进入prepared阶段；
> 2. 事务预提交。参与者收到PreCommit请求后，会执行事务操作，并将Undo和Redo日志写入本机事务日志；
> 3. 各参与者成功执行事务操作，同时将反馈以Ack响应形式发送给协调者，同事等待最终的Commit或Abort指令。
> 
> 中断事务
> 加入任意一个参与者向协调者发送No响应，或者等待超时，协调者在没有得到所有参与者响应时，即可以中断事务：
> 
> 1. 发送中断请求。 协调者向所有参与者发送Abort请求；
> 2. 中断事务。无论是收到协调者的Abort请求，还是等待协调者请求过程中出现超时，参与者都会中断事务；
> ```
> 
> 阶段三：doCommit
> 
> ```
> 在这个阶段，会真正的进行事务提交，同样存在两种可能。
> 
> 执行提交
> 1. 发送提交请求。假如协调者收到了所有参与者的Ack响应，那么将从预提交转换到提交状态，并向所有参与者，发送doCommit请求；
> 2. 事务提交。参与者收到doCommit请求后，会正式执行事务提交操作，并在完成提交操作后释放占用资源；
> 3. 反馈事务提交结果。参与者将在完成事务提交后，向协调者发送Ack消息；
> 4. 完成事务。协调者接收到所有参与者的Ack消息后，完成事务。
> 
> 中断事务
> 在该阶段，假设正常状态的协调者接收到任一个参与者发送的No响应，或在超时时间内，仍旧没收到反馈消息，就会中断事务：
> 
> 1. 发送中断请求。协调者向所有的参与者发送abort请求；
> 2. 事务回滚。参与者收到abort请求后，会利用阶段二中的Undo消息执行事务回滚，并在完成回滚后释放占用资源；
> 3. 反馈事务回滚结果。参与者在完成回滚后向协调者发送Ack消息；
> 4. 中端事务。协调者接收到所有参与者反馈的Ack消息后，完成事务中断。
> ```

**2PC和3PC的区别：**

三阶段提交协议在协调者和参与者中都引入 **超时机制**，并且把两阶段提交协议的第一个阶段拆分成了两步：询问，然后再锁资源，最后真正提交。三阶段提交的三个阶段分别为：can_commit，pre_commit，do_commit

## 可靠消息最终一致性

1. 什么是可靠消息最终一致性事务？

> 可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方(消息消费者)一定能够接收消息并处理事务成功，此方案强调的是**只要消息发给事务参与方最终事务要达到一致**。

2. 怎么实现？
   
   > 利用消息中间件完成。

3. 有哪些问题？
   
   > - 本地事务与消息原子性的问题
   >   
   >   事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息。即实现本地事务和消息发送的原子性，要么都成功，要么都失败。本地事务与消息发送的原子性问题是实现可靠消息最终一致性方案的关键问题。
   > 
   > 方案一：
   > 
   > ```
   > begin transaction；
   >    //1.发送MQ
   >    //2.数据库操作
   > commit transation;
   > ```
   > 
   > 这种情况下无法保证数据库操作与发送消息的一致性，因为可能发送消息成功，数据库操作失败。
   > 
   > 方案二：
   > 
   > ```
   > begin transaction；
   >    //1.数据库操作
   >    //2.发送MQ
   > commit transation;
   > ```
   > 
   > 这种情况下貌似没有问题，如果发送MQ消息失败，就会抛出异常，导致数据库事务回滚。但如果是超时异常（MQ发送但是确认超时），数据库回滚，但MQ其实已经正常发送了，同样会导致不一致。
   > 
   > - 事务参与方接收消息的可靠性
   >   
   >   事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息。
   > 
   > - 消息重复消费的问题
   >   
   >   若某一个消费节点超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重复消费。

4. 怎么解决这些问题？
   
   > - 本地消息表方案
   >   
   >   通过本地事务保证数据业务操作和消息的一致性，然后通过定时任务将消息发送至消息中间件，待确认消息发送给消费方成功再将消息删除。下面以注册送积分为例来说明：
   >   
   >   共有两个微服务，用户服务和积分服务，用户服务负责添加用户，积分服务负责增加积分：
   >   
   >   ![积分图](https://s2.loli.net/2022/03/26/T1jrKWOcUfH6gIL.png)
   >   
   >   交互流程如下：
   >   
   >   1. 用户注册
   >      
   >      用户服务在本地事务新增用户和增加 ”积分消息日志“。（用户表和消息表通过本地事务保证一致）
   >      
   >      下边是伪代码
   >      
   >      ```
   >      begin transaction；
   >         //1.新增用户
   >         //2.存储积分消息日志
   >      commit transation;
   >      ```
   >      
   >      这种情况下，本地数据库操作与存储积分消息日志处于同一个事务中，本地数据库操作与记录消息日志操作具备原子性。
   >   
   >   2. 定时任务扫描日志
   >      
   >      **如何保证将消息发送给消息队列呢**
   >      
   >      经过第一步消息已经写到消息日志表中，可以启动独立的线程，定时对消息日志表中的消息进行扫描并发送至消息中间件，在消息中间件反馈发送成功后删除该消息日志，否则等待定时任务下一周期重试。
   >   
   >   3. 消费消息
   >      
   >      **如何保证消费者一定能消费到消息呢？**
   >      
   >      　　这里可以使用MQ的ack（即消息确认）机制，消费者监听MQ，如果消费者接收到消息并且业务处理完成后向MQ发送ack（即消息确认），此时说明消费者正常消费消息完成，MQ将不再向消费者推送消息，否则消费者会不断重试向消费者来发送消息。积分服务接收到”增加积分“消息，开始增加积分，积分增加成功后向消息中间件回应ack，否则消息中间件将重复投递此消息。
   >      
   >      **由于消息会重复投递，积分服务的”增加积分“功能需要实现幂等性。**
   > 
   > - RocketMQ事务消息方案
   >   
   >   仍然以注册送积分为例
   >   
   >   1. 用户服务发送增加积分事务消息，MQ Server将消息状态标记为Prepared（预备状态），注意此时这条消息消费者（积分服务）是无法消费到的。
   >   2. 接收到MQ的成功消息后，用户服务提交本地事务添加用户
   >   3. 如果添加成功，像MQ发送commit消息，MQ接到消息后将”增加积分消息“ 状态标记为可消费，此时积分服务正常消费消息；添加失败像MQ发送回滚消息，删除增加积分消息
   >   4. 积分服务消费消息，消费成功则向MQ回应ack，否则将重复接收消息。这里ack默认自动回应，即程序执行正常则自动回应ack。
   >   5. 如果执行Producer端本地事务过程中，执行端挂掉，或者超时，MQ Server将会不停的询问同组的其他 Producer 来获取事务执行状态，这个过程叫事务回查。MQ Server会根据事务回查结果来决定是否投递消息。

5. 基于以上理论实现转账交易
   
   > 背景：A银行的李三给B银行的李四转钱
   > 
   > 方案：A行扣钱并通过消息队列通知B行
   > 
   > AB行库表一样
   > 
   > ```sql
   > CREATE TABLE `account_info`    (
   >    `id` bigint(20) NOT NULL AUTO_INCREMENT,
   >    `account_name` varchar(100) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT '户主姓名',
   >    `account_no` varchar(100) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT '银行卡号',
   >    `account_password` varchar(100) CHARACTER SET utf8 COLLATE utf8_bin NULL DEFAULT NULL COMMENT '帐户密码',
   >    `account_balance` double NULL DEFAULT NULL COMMENT '帐户余额', PRIMARY KEY (`id`) USING BTREE
   > )    ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8 COLLATE = utf8_bin ROW_FORMAT = Dynamic;
   > ```
   > 
   > 两行还分别有一个交易记录表用于去重
   > 
   > ```sql
   > CREATE TABLE `de_duplication`    (
   >    `tx_no`    varchar(64) COLLATE utf8_bin NOT NULL,
   >    `create_time` datetime(0) NULL DEFAULT NULL,
   >    PRIMARY KEY (`tx_no`) USING BTREE
   > ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_bin ROW_FORMAT = Dynamic;
   > ```
   > 
   > A行代码
   > 
   > Dao
   > 
   > ```java
   > @Mapper
   > @Component
   > public interface AccountInfoDao {
   > 
   >    @Update("update account_info set account_balance=account_balance+#{amount} where account_no=# {accountNo}")//更新账户金额
   >    int updateAccountBalance(@Param("accountNo") String accountNo, @Param("amount") Double amount);
   > 
   >    @Select("select count(1) from de_duplication where tx_no = #{txNo}")
   >    int isExistTx(String txNo);//查询交易记录表
   > 
   >    @Insert("insert into de_duplication values(#{txNo},now());")
   >    int addTx(String txNo);//插入交易记录表
   > }
   > ```
   > 
   > Service
   > 
   > ```java
   > @Service
   > @Slf4j
   > public class AccountInfoServiceImpl implements AccountInfoService {
   >    @Resource
   >    private RocketMQTemplate rocketMQTemplate;
   > 
   >    @Autowired
   >    private AccountInfoDao accountInfoDao;
   > 
   >    /**
   >    *    更新帐号余额‐发送消息
   >    *    producer向MQ Server发送消息
   >    *    
   >    *    @param accountChangeEvent
   >    */
   >    @Override
   >    public void sendUpdateAccountBalance(AccountChangeEvent accountChangeEvent) { //构建消息体
   >        JSONObject jsonObject = new JSONObject(); 
   >        jsonObject.put("accountChange",accountChangeEvent); 
   >        Message<String> message =MessageBuilder.withPayload(jsonObject.toJSONString()).build(); 
   >        TransactionSendResult sendResult =rocketMQTemplate.sendMessageInTransaction("producer_group_txmsg_bank1", "topic_txmsg", message, null);
   >        log.info("send transcation message body={},result= {}",message.getPayload(),sendResult.getSendStatus());
   >    }
   > 
   >    /**
   >    *    更新帐号余额‐本地事务
   >    *    producer发送消息完成后接收到MQ Server的回应即开始执行本地事务
   >    *
   >    *    @param accountChangeEvent
   >    */
   >    @Transactional
   >    @Override
   >    public void doUpdateAccountBalance(AccountChangeEvent accountChangeEvent) { log.info("开始更新本地事务，事务号：{}",accountChangeEvent.getTxNo());
   >        accountInfoDao.updateAccountBalance(accountChangeEvent.getAccountNo(),accountChangeEvent.getAmount() * ‐1);
   >        //为幂等作准备
   >        accountInfoDao.addTx(accountChangeEvent.getTxNo()); 
   >        if(accountChangeEvent.getAmount() == 2){
   >            throw new RuntimeException("bank1更新本地事务时抛出异常");
   >        }
   >        log.info("结束更新本地事务，事务号：{}",accountChangeEvent.getTxNo());
   >    }
   > }
   > ```
   > 
   > RocketMQLocalTransactionListener
   > 
   > ```java
   > @Component
   > @Slf4j
   > @RocketMQTransactionListener(txProducerGroup = "producer_group_txmsg_bank1") 
   > public class ProducerTxmsgListener implements RocketMQLocalTransactionListener {
   > 
   >    @Autowired
   >    AccountInfoService accountInfoService;
   > 
   >    @Autowired
   >    AccountInfoDao accountInfoDao;
   > 
   >    //prepare消息发送成功回调此方法，此方法执行本地事务
   >    @Override
   >    @Transactional
   >    public RocketMQLocalTransactionState executeLocalTransaction(Message message, Object arg) { 
   >    //解析消息内容
   >    try {
   >            String jsonString = new String((byte[]) message.getPayload()); 
   >            JSONObject jsonObject = JSONObject.parseObject(jsonString); 
   >            AccountChangeEvent accountChangeEvent =JSONObject.parseObject(jsonObject.getString("accountChange"), AccountChangeEvent.class);
   >            //扣除金额
   >            accountInfoService.doUpdateAccountBalance(accountChangeEvent);
   >      //执行成功后确认消息让B行看到
   >            return RocketMQLocalTransactionState.COMMIT;
   >        } catch (Exception e) { 
   >            log.error("executeLocalTransaction 事务执行失败",e); 
   >            e.printStackTrace();
   >      //不成功则回滚
   >            return RocketMQLocalTransactionState.ROLLBACK;
   >        }
   >    }
   > 
   >    //此方法检查事务执行状态，避免执行本地事务时机器挂掉
   >    @Override
   >    public RocketMQLocalTransactionState checkLocalTransaction(Message message) { 
   >        RocketMQLocalTransactionState state;
   >        final JSONObject jsonObject = JSON.parseObject(new String((byte[])
   >        message.getPayload()));
   >        AccountChangeEvent accountChangeEvent =JSONObject.parseObject(jsonObject.getString("accountChange"),AccountChangeEvent.class);
   >        //事务id
   >        String txNo = accountChangeEvent.getTxNo();
   >        int isexistTx = accountInfoDao.isExistTx(txNo);
   >        log.info("回查事务，事务号: {} 结果: {}", accountChangeEvent.getTxNo(),isexistTx); 
   >        if(isexistTx>0){
   >            state= RocketMQLocalTransactionState.COMMIT; 
   >        }else{
   >            state=    RocketMQLocalTransactionState.UNKNOWN;
   >        }
   >        return state;
   >    }
   > }
   > ```
   > 
   > Controller
   > 
   > ```java
   > @RestController
   > @Slf4j
   > public class AccountInfoController {
   > 
   >    @Autowired
   >    private AccountInfoService accountInfoService;
   > 
   >    @GetMapping(value = "/transfer")
   >    public String transfer(@RequestParam("accountNo")String accountNo,@RequestParam("amount") Double amount){
   >        String tx_no = UUID.randomUUID().toString();//转账前生成唯一订单号
   >        AccountChangeEvent accountChangeEvent = new AccountChangeEvent(accountNo,amount,tx_no);
   >        accountInfoService.sendUpdateAccountBalance(accountChangeEvent); return "转账成功";
   >    }
   > }
   > ```
   > 
   > B行代码
   > 
   > Service
   > 
   > ```java
   > @Service
   > @Slf4j
   > public class AccountInfoServiceImpl implements AccountInfoService {
   > 
   >    @Autowired
   >    AccountInfoDao accountInfoDao;
   > 
   > 
   >    /**
   >    *    消费消息，更新本地事务，添加金额
   >    *    @param accountChangeEvent
   >    */
   >    @Override
   >    @Transactional
   >    public void addAccountInfoBalance(AccountChangeEvent accountChangeEvent) { 
   >        log.info("bank2更新本地账号，账号：{},金额：{}",accountChangeEvent.getAccountNo(),accountChangeEvent.getAmount());
   >        //幂等校验
   >        int existTx = accountInfoDao.isExistTx(accountChangeEvent.getTxNo()); 
   >        if(existTx<=0){
   >            //执行更新
   >          accountInfoDao.updateAccountBalance(accountChangeEvent.getAccountNo(),accountChangeEvent.getAmoun t());
   >            //添加事务记录
   >            accountInfoDao.addTx(accountChangeEvent.getTxNo());
   >            log.info("更新本地事务执行成功，本次事务号: {}", accountChangeEvent.getTxNo()); }else{
   >            log.info("更新本地事务执行失败，本次事务号: {}", accountChangeEvent.getTxNo());
   >        }
   >    }
   > }
   > ```
   > 
   > MQ监听
   > 
   > ```java
   > @Component
   > @RocketMQMessageListener(topic = "topic_txmsg",consumerGroup = "consumer_txmsg_group_bank2") 
   > @Slf4j
   > public class TxmsgConsumer implements RocketMQListener<String> { 
   >    @Autowired
   >    AccountInfoService accountInfoService;
   > 
   >    @Override
   >    public void onMessage(String s) {
   >        log.info("开始消费消息:{}",s);
   >        //解析消息为对象
   >        final JSONObject jsonObject = JSON.parseObject(s); 
   >        AccountChangeEvent accountChangeEvent =JSONObject.parseObject(jsonObject.getString("accountChange"),AccountChangeEvent.class);
   >        //调用service增加账号金额
   >        accountChangeEvent.setAccountNo("2");
   >        accountInfoService.addAccountInfoBalance(accountChangeEvent);
   >    }
   > }
   > ```
   > 
   > 测试：
   > 
   > bank1本地事务失败，则bank1不发送转账消息。
   > 
   > bank2接收转账消息失败，会进行重试发送消息。
   > 
   > bank2多次消费同一个消息，实现幂等。

6. 总结
   
   可靠消息最终一致性就是保证消息从生产方经过消息中间件传递到消费方的一致性，本案例使用了RocketMQ作为消息中间件，RocketMQ主要解决了两个功能：
   
   - 本地事务与消息发送的原子性问题。
   - 事务参与方接收消息的可靠性。
   
   可靠消息最终一致性事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。

## 补偿型事务

可靠性消息最终一致性有一个问题，就是李四账户转账如果除了问题，那么怎么解决？答案是进行补偿型事务。

1. 补偿型事务流程
   
   > 正常成功流程
   > 
   > - A行扣减但是暂时不提交
   > - 远程调用B行服务
   > - 成功后A行才提交
   > 
   > 异常时额外发送远程调用到现金服务以加上之前扣掉的金额

## 尽最大努力通知

**最大努力通知事务**主要用于**外部系统**，因为外部的网络环境更加复杂和不可信，所以只能尽最大努力去通知实现数据最终一致性，**比如充值平台与运营商、支付对接、商户通知等等跨平台、跨企业的系统间业务交互场景**；

# 优化性能常见手段

- 中间件较多时，优化网络通信质量。
- 数据库查询耗时时，需要对查询进行优化，比如添加索引。
- 模板的渲染速度，可以通过设置模板缓存。
- 静态资源的获取，可以通过 Nginx 动静分离来解决。（下期再讲）
- 日志太多，需要减少不必要的打 log 操作。

# 数据压缩

HashMap<Integer, V>   ->  IntObjectHashMap<V>

Set<Integer> -> intSet

IntObjectHashMap，这个类出自 Netty，根据https://www.bilibili.com/video/BV1eX4y1F7zJ?p=2的测算，存入10000个数据，开销降低40%-60%

IntSet节省80%，不生成Integer对象，GC性能更好

- IntObjectHashMap对key冲突时使用的是开放寻址策略中的线性探测
- 它的key限制了就是int类型的值，所以初始化时不能指定key的类型
- 它内部有key[],value[]两个数组

HashMap的结构是 Node[] table; Node 下面有Hash，Key，Value，Next四个属性。
而IntObjectHashMap的结构是int[] keys 和 Object[] values.
在插入时，同样把int先取模落桶，如果遇到冲突，则不采样HashMap的链地址法，而是用开放地址法（线性探测法）index＋1找下一个空桶，最后在keys[index]，values[index]中分别记录。在查找时也是先落桶，然后在key[index++]中逐个比较key。
所以，对比整个数据结构，省的不止是int vs Integer，还有每个Node的内容。
而性能嘛，IntObjectHashMap还是稳赢一点的，随便测了几种场景，耗时至少都有24ms vs 28ms的样子，好的时候甚至快1/3。

# CQRS

Command Query Responsibility Segregation（命令查询职责隔离）

例如电商系统，包含订单、用户、商品等等数据，数据的变更操作、查询操作，都是基于这一套数据模型的。但是，实际场景下的查询需求是多种多样。例如这3类人群：

- 商家
- 买家用户
- 电商运营人员

他们的数据视角是不同的，各自的关注角度不同，需要查询的数据就完全不同，但数据模型是一套啊，怎么办？是不是就需要做数据关联、构建临时数据集合等等复杂的操作啊，基于一种数据模型，来实现 N 种视角的查询，既别扭又麻烦。

- CQRS 把数据的变更和查询拆开了，有各自的数据模型。

- 命令模型负责数据的变更，并把最新数据同步给查询模型。

- 查询模型根据自己的想法来安排数据，想怎么用就怎么用。

- 好处是可以让查询更加自由，更快的满足多变的业务需求。

- 坏处是增加了架构的复杂度，还有数据同步带来的问题。

# 一致性哈希

利用哈希去缓存

- 问题？

我们希望有同样ID的请求打到同样的机器上，这可能是因为那台机器有对应的缓存，也可能是因为那台机器上有上下文只有那台机器才能处理

- 怎么办？

将ID做哈希，哈希到不同机器

- 有一台机器崩了还能用吗？

不行了，10台机器，原本ID14的取模到4，4号机器崩了，5-10号顺序往前进一位，ID14号打到了原本的5号机器上，

而且大于4号的都不行了，这会引发大规模报错、大规模缓存雪崩

- 那我不对服务器数取模，对一个固定的数字取模不行吗？

那咋扩容、缩容，而且原来模4的请求不是都不能用吗

- 那把10台机器分布到一个2^32-1的哈希环上，用IP什么的对2^32-1进行取模，分布上去，我再用ID取模也放到哈希环上，然后顺时针找最近的机器搞上去，所有请求都这么搞，当一台机器挂了的时候，原本应该到这台的请求到了顺时针下一台，其余的不受影响，这样可以吗？

可以是可以，但是你就10台机器，对2^32取模以后差不多集中在环上的一个部分，但是请求ID有123456781234567123456这么长，一取模，大部分估计都落到了一台上，那台机器要是挂了，咋办?

- 那把那10台服务器弄点虚拟节点出来，放在哈希环的空白处，每个虚拟他个100000台，均匀撒在环上的空白处能行吗？

这样倒是可以，咋虚拟？

- [.........NodeA1............NodeA2...............NodeA3.............]顺时针找，碰到带序号的都给映射回不带序号的节点去

一致性哈希在发布时、增减机器时怎么办?

- 实际上根据ip+节点做哈希，只要ip不变虚拟节点倍数不变，那么他的位置就不会变，增减节点时就可以只在特定的位置做增减
- 每次服务注册会拉取节点到本地，通过对比确定是不是要重建hash环

```java
@Data
@AllArgsConstructor
public class ServerNode {
    private String name;
    private Integer weight;
}


/**
 * 一致性哈希,这个一致性哈希其实是一个treemap<位置，node>，位置都是虚拟出来的，
 * 虚拟位置用的是hash(ip+要虚拟多少个的序号)
 * */
public class sss {
    TreeMap<Long, String> newBuckets = new TreeMap<>();
    public void freshServers(List<ServerNode> serverNodes) {
        String[] newServers = new String[serverNodes.size()];
        int[] weights = new int[serverNodes.size()];
        int totalWeight = 0;

        for (int i = 0; i < serverNodes.size(); i++) {
            ServerNode serverNode = serverNodes.get(i);
            newServers[i] = serverNode.getName();
            weights[i] = serverNode.getWeight();
            if (weights[i] <= 0) {
                weights[i] = 1;
            }
            totalWeight += weights[i];
        }
        if (totalWeight <= 0) {
            totalWeight = 1;
        }
        MessageDigest md5;
        try {
            md5 = MessageDigest.getInstance("MD5");
        } catch (NoSuchAlgorithmException e) {
            return;
        }
        System.out.println("total weight:"+totalWeight);
        for (int i = 0; i < newServers.length; i++) {
            // 根据weight占比设置40倍虚拟节点，10个节点的话就总共有400个虚拟节点，factor表示第i个节点要设置多少虚拟节点
            double factor = Math.floor(((double) (40 * newServers.length * weights[i])) / (double) totalWeight);
            System.out.println(newServers[i]+":"+factor);
            // 设置factor*4个虚拟节点
            for (long j = 0; j < factor; j++) {
                //每个节点算一个md5值
                byte[] d = md5.digest((newServers[i] + "-" + j).getBytes(StandardCharsets.UTF_8));
                //每个节点在哈希环上占据4*factor个位置
                for (int h = 0; h < 4; h++) {
                    Long nodePos =
                            ((long) (d[3 + h * 4] & 0xFF) << 24)
                                    | ((long) (d[2 + h * 4] & 0xFF) << 16)
                                    | ((long) (d[1 + h * 4] & 0xFF) << 8)
                                    | (d[1 + h * 4] & 0xFF);
                    newBuckets.put(nodePos, newServers[i]);//最终有1600个节点
                    System.out.println(nodePos+" "+newServers[i]);
                }
            }
        }
    }

    private String getSelectServerName(Long keyHash){
        //ceilingKey(K key)返回大于或等于给定键的最小键
        Long point = newBuckets.ceilingKey(keyHash);
        if (point == null) {
            point = newBuckets.firstKey();
        }
        return newBuckets.get(point);
    }

    Long md5HashingAlg(String key){
        MessageDigest md5;
        try{
            md5 = MessageDigest.getInstance("MD5");
        }catch (NoSuchAlgorithmException e){
            return hashKey(key);
        }
        md5.reset();
        md5.update(key.getBytes(StandardCharsets.UTF_8));
        byte[] bKey = md5.digest();
        return ((long) (bKey[3] & 0xFF) << 24)
                | ((long) (bKey[2] & 0xFF) << 16)
                | ((long) (bKey[1] & 0xFF) << 8) | (bKey[0] & 0xFF);
    }

    Long hashKey(String key){
        return Math.abs(key.hashCode() + 1L);
    }

    public static void main(String[] args) {
        sss sss = new sss();
        ArrayList<ServerNode> serverNodes = new ArrayList<>();
        for (int i = 1; i <= 10; i++) {
            serverNodes.add(new ServerNode("server"+i,i));
        }
        sss.freshServers(serverNodes);
        System.out.println(sss.md5HashingAlg("2132312-312312-12xsaxa"));
        System.out.println(sss.getSelectServerName(sss.md5HashingAlg("2132312-312312-12xsaxa")));
    }
}
```

# HTTP与RPC

- 长链接，不必每次通信都要像 http 一样去 3 次握手什么的，减少了网络开销
-  RPC 框架一般都有注册中心，有丰富的监控管理
- 发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作，主要是优雅下线等
- RPC 主要是基于 TCP/IP 协议的，而 HTTP 服务主要是基于 HTTP 协议的，我们都知道 HTTP 协议是在传输层协议 TCP 之上的，所以效率来看的话，RPC 当然是要更胜一筹

# 全链路压测

1. 数据库，采用影子表，发现是压测流量直接写到影子表
2. redis，影子Category，发现是压测流量写到影子category
3. tair，影子area，发现是压测流量写入影子area
4. kafka，根据消息是否带压测标志，决定是否生产、消费，还是直接丢弃
5. 限流，分流量限流，压测限压测的，实际限实际的

## 流量打标

- URL上进行打标
- HTTP Header上进行打标

## 打标在链路上传递

- 调用时获取，然后放在ThreadLocal中，在RPC框架、中间件代理中放入请求中一直往下传

## 外部接口

- 走mock

## 数据构造

- 录制
- 从hive表构造

## 发起压测

- 走压测平台

# 基于Hystrix实现高可用

## 基于Hystrix线程池实现资源隔离

- 利用HystrixCommond获取单条数据

  ```java
  //这里我们可以简单认为这是一个线程池，每次调用商品服务，就只会用该线程池中的资源，不会再去用其它线程资源了。
  public class GetProductInfoCommand extends HystrixCommand<ProductInfo> {
  
      private Long productId;
  
      public GetProductInfoCommand(Long productId) {
          //command group 是一个非常重要的概念，默认情况下，就是通过 command group 来定义一个线程池的，而且还会通过 command group 来聚合一些监控和报警信息。同一个 command group 中的请求，都会进入同一个线程池中。
          super(HystrixCommandGroupKey.Factory.asKey("GetProductInfoCommandGroup"));
          this.productId = productId;
      }
  
      @Override
      protected ProductInfo run() {
          String url = "http://localhost:8081/getProductInfo?productId=" + productId;
          // 调用商品服务接口
          String response = HttpClientUtils.sendGetRequest(url);
          return JSONObject.parseObject(response, ProductInfo.class);
      }
  }
  
  @RequestMapping("/getProductInfo")
  @ResponseBody
  public String getProductInfo(Long productId) {
      HystrixCommand<ProductInfo> getProductInfoCommand = new GetProductInfoCommand(productId);
  
      // 通过command执行，获取最新商品数据
      ProductInfo productInfo = getProductInfoCommand.execute();
      System.out.println(productInfo);
      return "success";
  }
  ```

  上面执行的是 execute() 方法，其实是同步的。也可以对 command 调用 queue() 方法，它仅仅是将 command 放入线程池的一个等待队列，就立即返回，拿到一个 Future 对象，后面可以继续做其它一些事情，然后过一段时间对 Future 调用 get() 方法获取数据。这是异步的。

  >本质上来看，command就像是一个线程池，可以设置这个线程池，也可以设置哪些服务、哪些接口共用或者单独使用这个线程池，一些设置线程池的方法比如核心线程数、拒绝策略也可以用到这里

- 利用 HystrixObservableCommand 批量获取数据

  只要是获取商品数据，全部都绑定到同一个线程池里面去，我们通过 HystrixObservableCommand 的一个线程去执行，而在这个线程里面，批量把多个 productId 的 productInfo 拉回来。

  ```java
  public class GetProductInfosCommand extends HystrixObservableCommand<ProductInfo> {
  
      private String[] productIds;
  
      public GetProductInfosCommand(String[] productIds) {
          // 还是绑定在同一个线程池
          super(HystrixCommandGroupKey.Factory.asKey("GetProductInfoGroup"));
          this.productIds = productIds;
      }
  
      @Override
      protected Observable<ProductInfo> construct() {
          return Observable.unsafeCreate((Observable.OnSubscribe<ProductInfo>) subscriber -> {
  
              for (String productId : productIds) {
                  // 批量获取商品数据
                  String url = "http://localhost:8081/getProductInfo?productId=" + productId;
                  String response = HttpClientUtils.sendGetRequest(url);
                  ProductInfo productInfo = JSONObject.parseObject(response, ProductInfo.class);
                  subscriber.onNext(productInfo);
              }
              subscriber.onCompleted();
  
          }).subscribeOn(Schedulers.io());
      }
  }
  ```

  ```java
  public class GetProductInfosCommand extends HystrixObservableCommand<ProductInfo> {
  
      private String[] productIds;
  
      public GetProductInfosCommand(String[] productIds) {
          // 还是绑定在同一个线程池
          super(HystrixCommandGroupKey.Factory.asKey("GetProductInfoGroup"));
          this.productIds = productIds;
      }
  
      @Override
      protected Observable<ProductInfo> construct() {
          return Observable.unsafeCreate((Observable.OnSubscribe<ProductInfo>) subscriber -> {
  
              for (String productId : productIds) {
                  // 批量获取商品数据
                  String url = "http://localhost:8081/getProductInfo?productId=" + productId;
                  String response = HttpClientUtils.sendGetRequest(url);
                  ProductInfo productInfo = JSONObject.parseObject(response, ProductInfo.class);
                  subscriber.onNext(productInfo);
              }
              subscriber.onCompleted();
  
          }).subscribeOn(Schedulers.io());
      }
  }
  
  //在缓存服务接口中，根据传来的 id 列表，比如是以 , 分隔的 id 串，通过上面的 HystrixObservableCommand，执行 Hystrix 的一些 API 方法，获取到所有商品数据。
  public String getProductInfos(String productIds) {
      String[] productIdArray = productIds.split(",");
      HystrixObservableCommand<ProductInfo> getProductInfosCommand = new GetProductInfosCommand(productIdArray);
      Observable<ProductInfo> observable = getProductInfosCommand.observe();
  
      observable.subscribe(new Observer<ProductInfo>() {
          @Override
          public void onCompleted() {
              System.out.println("获取完了所有的商品数据");
          }
  
          @Override
          public void onError(Throwable e) {
              e.printStackTrace();
          }
  
          /**
           * 获取完一条数据，就回调一次这个方法
           * @param productInfo
           */
          @Override
          public void onNext(ProductInfo productInfo) {
              System.out.println(productInfo);
          }
      });
      return "success";
  }
  ```

## 基于 Hystrix 信号量机制实现资源隔离

- 信号量机制

  信号量的资源隔离只是起到一个开关的作用，比如，服务 A 的信号量大小为 10，那么就是说它同时只允许有 10 个 tomcat 线程来访问服务 A，其它的请求都会被拒绝，从而达到资源隔离和限流保护的作用。

- 线程池与信号量区别

  线程池隔离技术，并不是说去控制类似 tomcat 这种 web 容器的线程。更加严格的意义上来说，Hystrix 的线程池隔离技术，控制的是 tomcat 线程的执行。Hystrix 线程池满后，会确保说，tomcat 的线程不会因为依赖服务的接口调用延迟或故障而被 hang 住，tomcat 其它的线程不会卡死，可以快速返回，然后支撑其它的事情。

  线程池隔离技术，是用 Hystrix 自己的线程去执行调用；而信号量隔离技术，是直接让 tomcat 线程去调用依赖服务。信号量隔离，只是一道关卡，信号量有多少，就允许多少个 tomcat 线程通过它，然后去执行。

- 适用场景

  - **线程池技术**，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的 timeout 进行控制（捕捉 timeout 超时异常）。
  - **信号量技术**，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。

- 信号量简单例子

  一般我们在获取到商品数据之后，都要去获取商品是属于哪个地理位置、省、市、卖家等，可能在自己的纯内存中，比如就一个 Map 去获取。对于这种直接访问本地内存的逻辑，比较适合用信号量做一下简单的隔离。

  ```java
  public class LocationCache {
      private static Map<Long, String> cityMap = new HashMap<>();
  
      static {
          cityMap.put(1L, "北京");
      }
  
      /**
       * 通过cityId 获取 cityName
       *
       * @param cityId 城市id
       * @return 城市名
       */
      public static String getCityName(Long cityId) {
          return cityMap.get(cityId);
      }
  }
  
  public class GetCityNameCommand extends HystrixCommand<String> {
  
      private Long cityId;
  
      public GetCityNameCommand(Long cityId) {
          // 设置信号量隔离策略
          super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("GetCityNameGroup"))
                  .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()
                          .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE)));
  
          this.cityId = cityId;
      }
  
      @Override
      protected String run() {
          // 需要进行信号量隔离的代码
          return LocationCache.getCityName(cityId);
      }
  }
  
  @RequestMapping("/getProductInfo")
  @ResponseBody
  public String getProductInfo(Long productId) {
      HystrixCommand<ProductInfo> getProductInfoCommand = new GetProductInfoCommand(productId);
  
      // 通过command执行，获取最新商品数据
      ProductInfo productInfo = getProductInfoCommand.execute();
  
      Long cityId = productInfo.getCityId();
  
      GetCityNameCommand getCityNameCommand = new GetCityNameCommand(cityId);
      // 获取本地内存(cityName)的代码会被信号量进行资源隔离
      String cityName = getCityNameCommand.execute();
  
      productInfo.setCityName(cityName);
  
      System.out.println(productInfo);
      return "success";
  }
  ```

  ## 服务降级

  Hystrix 出现以下四种情况，都会去调用 fallback 降级机制：

  - 断路器处于打开的状态。
  - 资源池已满（线程池+队列 / 信号量）。
  - Hystrix 调用各种接口，或者访问外部依赖，比如 MySQL、Redis、Zookeeper、Kafka 等等，出现了任何异常的情况。
  - 访问外部依赖的时候，访问时间过长，报了 TimeoutException 异常。

  ### 两种最经典的降级机制

  - 纯内存数据
    在降级逻辑中，你可以在内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内。如果说外部依赖有异常，fallback 这里直接尝试从 ehcache 中获取数据。
  - 默认值
    fallback 降级逻辑中，也可以直接返回一个默认值。

  在 `HystrixCommand`，降级逻辑的书写，是通过实现 getFallback() 接口；而在 `HystrixObservableCommand` 中，则是实现 resumeWithFallback() 方法。

  现在，我们用一个简单的栗子，来演示 fallback 降级是怎么做的。

  比如，有这么个**场景**。我们现在有个包含 brandId 的商品数据，假设正常的逻辑是这样：拿到一个商品数据，根据 brandId 去调用品牌服务的接口，获取品牌的最新名称 brandName。

  假如说，品牌服务接口挂掉了，那么我们可以尝试从本地内存中，获取一份稍过期的数据，先凑合着用。

  ### 步骤一：本地缓存获取数据

  本地获取品牌名称的代码大致如下。

  ```java
  /**
   * 品牌名称本地缓存
   *
   */
  
  public class BrandCache {
  
      private static Map<Long, String> brandMap = new HashMap<>();
  
      static {
          brandMap.put(1L, "Nike");
      }
  
      /**
       * brandId 获取 brandName
       *
       * @param brandId 品牌id
       * @return 品牌名
       */
      public static String getBrandName(Long brandId) {
          return brandMap.get(brandId);
      }
  ```

  ### 步骤二：实现 GetBrandNameCommand

  在 GetBrandNameCommand 中，run() 方法的正常逻辑是去调用品牌服务的接口获取到品牌名称，如果调用失败，报错了，那么就会去调用 fallback 降级机制。

  这里，我们直接**模拟接口调用报错**，给它抛出个异常。

  而在 getFallback() 方法中，就是我们的**降级逻辑**，我们直接从本地的缓存中，**获取到品牌名称**的数据。

  ```java
  /**
   * 获取品牌名称的command
   *
   */
  public class GetBrandNameCommand extends HystrixCommand<String> {
  
      private Long brandId;
  
      public GetBrandNameCommand(Long brandId) {
          super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey("BrandService"))
                  .andCommandKey(HystrixCommandKey.Factory.asKey("GetBrandNameCommand"))
                  .andCommandPropertiesDefaults(HystrixCommandProperties.Setter()
                          // 设置降级机制最大并发请求数
                          .withFallbackIsolationSemaphoreMaxConcurrentRequests(15)));
          this.brandId = brandId;
      }
  
      @Override
      protected String run() throws Exception {
          // 这里正常的逻辑应该是去调用一个品牌服务的接口获取名称
          // 如果调用失败，报错了，那么就会去调用fallback降级机制
  
          // 这里我们直接模拟调用报错，抛出异常
          throw new Exception();
      }
  
      @Override
      protected String getFallback() {
          return BrandCache.getBrandName(brandId);
      }
  }
  ```

  `FallbackIsolationSemaphoreMaxConcurrentRequests` 用于设置 fallback 最大允许的并发请求量，默认值是 10，是通过 semaphore 信号量的机制去限流的。如果超出了这个最大值，那么直接 reject。

  ### 步骤三：CacheController 调用接口

  在 CacheController 中，我们通过 productInfo 获取 brandId，然后创建 GetBrandNameCommand 并执行，去尝试获取 brandName。这里执行会报错，因为我们在 run() 方法中直接抛出异常，Hystrix 就会去调用 getFallback() 方法走降级逻辑。

  ```java
  @Controller
  public class CacheController {
  
      @RequestMapping("/getProductInfo")
      @ResponseBody
      public String getProductInfo(Long productId) {
          HystrixCommand<ProductInfo> getProductInfoCommand = new GetProductInfoCommand(productId);
  
          ProductInfo productInfo = getProductInfoCommand.execute();
          Long brandId = productInfo.getBrandId();
  
          HystrixCommand<String> getBrandNameCommand = new GetBrandNameCommand(brandId);
  
          // 执行会抛异常报错，然后走降级
          String brandName = getBrandNameCommand.execute();
          productInfo.setBrandName(brandName);
  
          System.out.println(productInfo);
          return "success";
      }
  }
  ```

- 降级回复机制

  ##### 1、立即恢复

  即放全部流量到ServiceD；

  ##### 2、正常恢复

  默认策略，即每秒恢复1%的流量，这种速度比较慢；

  ##### 3、快速恢复

  即按2的幂次方恢复流量，按每秒 2%、4%、8%、16%、32%、64%，100%的速度恢复；

  ##### 4、指定时间

  即在规定时间内恢复完成，恢复速度是匀速的；

  | 对应管理端配置     | 说明                                                         |
  | :----------------- | :----------------------------------------------------------- |
  | 是否开启           | 熔断器总开关，关闭后（false）熔断器失效                      |
  | 手动熔断           | 强制熔断开关，打开时(true)，按照下面的“降级比率”降级。       |
  | 降级比率           | 当“手动熔断”开启时，通过的的流量按照当前配置的降级比率走降级逻辑。比如，设置为100%时，表示所有的流量都走降级逻辑；设置为0%时，表示所有的流量都不走降级逻辑。 |
  | 熔断前异常处理策略 | 在自动熔断开启之前，对异常的处理方式，当发生异常时，可以选择抛出该异常，或者捕获，走降级逻辑，这种配置只对注解方式接入的有效。 |
  | 请求试探窗口       | 请求试探窗口。自动熔断之后，定期试探接口是否恢复正常。每个请求试探窗口的时间范围内的第一个请求会被标记为试探请求，如果试探成功，则尝试恢复流量，默认是5s |
  | 超时时间设置       | 设置请求最大响应时间，如果超时会中断当前线程，并抛出RhinoTimeOutException。默认为0，即不会超时检测 |
  | 信号量             | 设置最大并发数，即执行了CircuitBreaker.allowRequest()，但是还没有执行CircuitBreaker.complete()的请求数量。 |

## JWT

- 一个JWT**(java web token)**由三部分组成

  - Header(头部)——base64编码当然Json字符串，里边说明类型和使用的算法
  - Payload(载荷)——base64编码的Json字符串，里边存放有效信息
  - Signature(签名)——使用指定算法，通过Header和Payload加盐计算的字符串

  各部分以”.“分隔，例如

  `eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ3eWoiLCJleHAiOjE2MDI0MTU0NTUsImlhdCI6MTYwMjQxMzY1NX0.gNZZdUztdC9qwzInC_wyYA5dGbAHps6i2yy_5_7IVE4`

  直接通过base64解码即可获得[base64在线加解密](https://tool.oschina.net/encrypt?type=3)，上述JWT的Header和Payload分别为

  ` {"alg":"HS256"}{"sub":"wyj","exp":1602415455,"iat":1602413655}`

  请求的时候在HTTP的headers参数里面的authorization里边，值的前面加`Bearer`关键字和空格，除此之外也可以在url和request body中传递

  ## Header

  如上所示，Header里主要说明类型和使用算法

  ## Payload

  ### 标准中注册的声明

  - iss： jwt签发者
  - sub: jwt所面向的用户
  - aud: 接收jwt的一方
  - exp: jwt的过期时间，这个过期时间必须要大于签发时间
  - nbf: 定义在什么时间之前，该jwt都是不可用的.
  - iat: jwt的签发时间
  - jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击

  ### 公共的声明

  可以添加任何信息，但不建议添加敏感信息

  ### 私有的声明

  私有声明是提供者和消费者所共同定义的声明

  ## Signature

  ```java
  encodedString = base64UrlEncode(header) + '.' + base64UrlEncode(payload);
  signature = HMACSHA256(encodedString, 'secret');
  ```

  其中的**’secret‘**是服务端的私钥，需要严格保密，如果客户端获得了这个秘钥，那就可以自己签发token了。**服务端主要通过第三部分来确认这个token确实是服务端签发的，因为只有服务端能通过秘钥根据Header与Payload验证重新加密对比签名**。

  ## 签名算法

  HS256:对称签名

  RS256:非对称签名

## 客户端不可信

- 客户端的计算不可信

  ```java
  //客户端计算了商品总价
  @PostMapping("/order")
  public void wrong(@RequestBody Order order) {
      this.createOrder(order);
  }
  
  @Data
  public class Order {
      private long itemId; //商品ID
      private BigDecimal itemPrice; //商品价格
      private int quantity; //商品数量
      private BigDecimal itemTotalPrice; //商品总价
  }
  //服务端如果直接拿来用，会有被黑客攻击的风险
  //正确的做法是服务端校验给出提示或者服务端计算客户端再比较给出提示
  @Data
  public class CreateOrderRequest {
      private long itemId; //商品ID
      private int quantity;  //商品数量
  }
  
  @PostMapping("orderRight2")
  public Order right2(@RequestBody CreateOrderRequest createOrderRequest) {
      //商品ID和商品数量是可信的没问题，其他数据需要由服务端计算
      Item item = Db.getItem(createOrderRequest.getItemId());
      Order order = new Order();
      order.setItemPrice(item.getItemPrice());
   order.setItemTotalPrice(item.getItemPrice().multiply(BigDecimal.valueOf(order.getQuantity())));
      createOrder(order);
      return order;
  }
  ```

- 客户端提交的参数需要校验

  ```java
  //容易忽略的一点是，误以为客户端的数据来源是服务端，客户端就不可能提交异常数据
  //可以使用断言、抛异常、Spring Validation等方式校验
  //一个更容易忽略的点是，我们可能会把一些服务端的数据暂存在网页的隐藏域中，这样下次页面提交的时候可以把相关数据再传给服务端。虽然用户通过网页界面的操作无法修改这些数据，但这些数据对于HTTP请求来说就是普通数据，完全可以随时修改为任意值。所以，服务端在使用这些数据的时候，也同样要特别小心。
  @GetMapping("right")
  public String right(@LoginRequired Long userId) {
      return "当前用户Id：" + userId;
  }
  
  @Retention(RetentionPolicy.RUNTIME)
  @Target(ElementType.PARAMETER)
  @Documented
  public @interface LoginRequired {
      String sessionKey() default "currentUser";
  }
  
  @Slf4j
  public class LoginRequiredArgumentResolver implements HandlerMethodArgumentResolver {
      //解析哪些参数
      @Override
      public boolean supportsParameter(MethodParameter methodParameter) {
          //匹配参数上具有@LoginRequired注解的参数
          return methodParameter.hasParameterAnnotation(LoginRequired.class);
      }
  
  @Override
  public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory) throws Exception {
          //从参数上获得注解
          LoginRequired loginRequired = methodParameter.getParameterAnnotation(LoginRequired.class);
          //根据注解中的Session Key，从Session中查询用户信息
          Object object = nativeWebRequest.getAttribute(loginRequired.sessionKey(), NativeWebRequest.SCOPE_SESSION);
          if (object == null) {
              log.error("接口 {} 非法调用！", methodParameter.getMethod().toString());
              throw new RuntimeException("请先登录！");
          }
          return object;
      }
  }
  
  public class CommonMistakesApplication implements WebMvcConfigurer {
      @Override
      public void addArgumentResolvers(List resolvers) {
          resolvers.add(new LoginRequiredArgumentResolver());
      }
  }
  ```

- 不能信任请求头里的任何内容

  ```java
  //通过用户的ip判断他是否领过奖品
  @Slf4j
  @RequestMapping("trustclientip")
  @RestController
  public class TrustClientIpController {
  
      HashSet activityLimit = new HashSet<>();
  
      @GetMapping("test")
      public String test(HttpServletRequest request) {
          String ip = getClientIp(request);
          if (activityLimit.contains(ip)) {
              return "您已经领取过奖品";
          } else {
              activityLimit.add(ip);
              return "奖品领取成功";
          }
      }
  //优先通过X-Forwarded-For请求头来获取，如果没有的话再通过HttpServletRequest的getRemoteAddr方法来获取。之所以这么做是因为，通常我们的应用之前都部署了反向代理或负载均衡器，remoteAddr获得的只能是代理的IP地址，而不是访问用户实际的IP。这不符合我们的需求，因为反向代理在转发请求时，通常会把用户真实IP放入X-Forwarded-For这个请求头中。
      private String getClientIp(HttpServletRequest request) {
          String xff = request.getHeader("X-Forwarded-For");
          if (xff == null) {
              return request.getRemoteAddr();
          } else {
              return xff.contains(",") ? xff.split(",")[0] : xff;
          }
      }
  }
  ```

  **这种过于依赖X-Forwarded-For请求头来判断用户唯一性的实现方式，是有问题的**：

  - 完全可以通过cURL类似的工具来模拟请求，随意篡改头的内容：

  ```
  curl http://localhost:45678/trustclientip/test -H "X-Forwarded-For:183.84.18.71, 10.253.15.1"
  ```

  - 网吧、学校等机构的出口IP往往是同一个，在这个场景下，可能只有最先打开这个页面的用户才能领取到奖品，而其他用户会被阻拦。

  因此，**IP地址或者说请求头里的任何信息，包括Cookie中的信息、Referer，只能用作参考，不能用作重要逻辑判断的依据。**而对于类似这个案例唯一性的判断需求，更好的做法是，让用户进行登录或三方授权登录（比如微信），拿到用户标识来做唯一性判断。

- 用户标识不能从客户端获取

  ```java
  @GetMapping("wrong")
  public String wrong(@RequestParam("userId") Long userId) {
      return "当前用户Id：" + userId;
  }
  //可以使用HandlerMethodArgumentResolver来处理登录
  ```

## 防刷、限量、防重

- 防刷

  对于类似于短信验证码这种开放接口，程序逻辑内需要有防刷逻辑。好的防刷逻辑是，对正常使用的用户毫无影响，只有疑似异常使用的用户才会感受到。对于短信验证码，有如下4种可行的方式来防刷。

  >第一种方式，**只有固定的请求头才能发送验证码。**
  >
  >也就是说，我们通过请求头中网页或App客户端传给服务端的一些额外参数，来判断请求是不是App发起的。其实，这种方式“防君子不防小人”。
  >
  >比如，判断是否存在浏览器或手机型号、设备分辨率请求头。对于那些使用爬虫来抓取短信接口地址的程序来说，往往只能抓取到URL，而难以分析出请求发送短信还需要的额外请求头，可以看作第一道基本防御。
  >
  >第二种方式，**只有先到过注册页面才能发送验证码。**
  >
  >对于普通用户来说，不管是通过App注册还是H5页面注册，一定是先进入注册页面才能看到发送验证码按钮，再点击发送。我们可以在页面或界面打开时请求固定的前置接口，为这个设备开启允许发送验证码的窗口，之后的请求发送验证码才是有效请求。
  >
  >这种方式可以防御直接绕开固定流程，通过接口直接调用的发送验证码请求，并不会干扰普通用户。
  >
  >第三种方式，**控制相同手机号的发送次数和发送频次。**
  >
  >除非是短信无法收到，否则用户不太会请求了验证码后不完成注册流程，再重新请求。因此，我们可以限制同一手机号每天的最大请求次数。验证码的到达需要时间，太短的发送间隔没有意义，所以我们还可以控制发送的最短间隔。比如，我们可以控制相同手机号一天只能发送10次验证码，最短发送间隔1分钟。
  >
  >第四种方式，**增加前置图形验证码。**
  >
  >短信轰炸平台一般会收集很多免费短信接口，一个接口只会给一个用户发一次短信，所以控制相同手机号发送次数和间隔的方式不够有效。这时，我们可以考虑对用户体验稍微有影响，但也是最有效的方式作为保底，即将弹出图形验证码作为前置。
  >
  >除了图形验证码，我们还可以使用其他更友好的人机验证手段（比如滑动、点击验证码等），甚至是引入比较新潮的无感知验证码方案（比如，通过判断用户输入手机号的打字节奏，来判断是用户还是机器），来改善用户体验。
  >
  >此外，我们也可以考虑在监测到异常的情况下再弹出人机检测。比如，短时间内大量相同远端IP发送验证码的时候，才会触发人机检测。
  >
  >总之，我们要确保，只有正常用户经过正常的流程才能使用开放平台资源，并且资源的用量在业务需求合理范围内。此外，还需要考虑做好短信发送量的实时监控，遇到发送量激增要及时报警。

- 虚拟资产并不能凭空产生无限使用

  >虚拟资产虽然是平台方自己生产和控制，但如果生产出来可以立即使用就有立即变现的可能性。比如，因为平台Bug有大量用户领取高额优惠券，并立即下单使用。
  >
  >在商家看来，这很可能只是一个用户支付的订单，并不会感知到用户使用平台方优惠券的情况；同时，因为平台和商家是事后结算的，所以会马上安排发货。而发货后基本就不可逆了，一夜之间造成了大量资金损失。
  >
  >**合适的做法是，把优惠券看作一种资源，其生产不是凭空的，而是需要事先申请**，理由是：
  >
  >- 虚拟资产如果最终可以对应到真实金钱上的优惠，那么，能发多少取决于运营和财务的核算，应该是有计划、有上限的。引言提到的无门槛优惠券，需要特别小心。有门槛优惠券的大量使用至少会带来大量真实的消费，而使用无门槛优惠券下的订单，可能用户一分钱都没有支付。
  >- 即使虚拟资产不值钱，大量不合常规的虚拟资产流入市场，也会冲垮虚拟资产的经济体系，造成虚拟货币的极速贬值。有量的控制才有价值。
  >- 资产的申请需要理由，甚至需要走流程，这样才可以追溯是什么活动需要、谁提出的申请，程序依据申请批次来发放。

- 防重（参见接口幂等性）

  >涉及钱的进出，需要做好以下两点。
  >
  >第一，**任何资金操作都需要在平台侧生成业务属性的订单，可以是优惠券发放订单，可以是返现订单，也可以是借款订单，一定是先有订单再去做资金操作**。同时，订单的产生需要有业务属性。业务属性是指，订单不是凭空产生的，否则就没有控制的意义。比如，返现发放订单必须关联到原先的商品订单产生；再比如，借款订单必须关联到同一个借款合同产生。
  >
  >第二，**一定要做好防重，也就是实现幂等处理，并且幂等处理必须是全链路的**。这里的全链路是指，从前到后都需要有相同的业务订单号来贯穿，实现最终的支付防重。

## 分离数据与代码

- SQL注入

  常见通过报错注入、布尔盲注、时间盲注和联合查询注入

  ```java
  //错误sql
  @Select("SELECT id,name FROM `userdata` WHERE name LIKE '%${name}%'")
  List findByNameWrong(@Param("name") String name);
  //正确的
  @Select("SELECT id,name FROM `userdata` WHERE name LIKE CONCAT('%',#{name},'%')")
  List findByNameRight(@Param("name") String name);
  //又比如IN子句。因为涉及多个元素的拼接，一些同学不知道如何处理，也可能会选择使用“${}”。因为使用“#{}”会把输入当做一个字符串来对待,修改方式是，给MyBatis传入一个List，然后使用其foreach标签来拼接出IN中的内容，并确保IN中的每一项都是使用“#{}”来注入参数
  ```

- 动态代码

  ```java
  return jsEngine.eval(String.format("var name='%s'; name=='admin'?1:0;", name));
  //haha';java.lang.System.exit(0);'
  //解决这个问题有两种方式。
  //第一种方式和解决SQL注入一样，需要把外部传入的条件数据仅仅当做数据来对待。我们可以通过SimpleBindings来绑定参数初始化name变量，而不是直接拼接代码：
  Map parm = new HashMap<>();
  parm.put("name", name);
  //name参数作为绑定传给eval方法，而不是拼接JavaScript代码
  return jsEngine.eval("name=='admin'?1:0;", new SimpleBindings(parm));
  //第二种解决方法是，使用SecurityManager配合AccessControlContext，来构建一个脚本运行的沙箱环境。脚本能执行的所有操作权限，是通过setPermissions方法精细化设置的
  ```

- XSS

  >@ControllerAdvice 
  >定义一个servlet Filter，通过HttpServletRequestWrapper实现servlet层面的统一参数替换
  >自定义序列化与反序列化
  >Cookie启用了HttpOnly属性  

## 敏感信息保存

- 密码

  >//Spring Security使用BCryptPasswordEncoder，也就是BCrypt来进行密码哈希。BCrypt是为保存密码设计的算法，相比MD5要慢很多。
  >
  >第一，我们调用encode、matches方法进行哈希、做密码比对的时候，不需要传入盐。BCrypt把盐作为了算法的一部分，强制我们遵循安全保存密码的最佳实践。
  >
  >第二，生成的盐和哈希后的密码拼在了一起：$是字段分隔符，其中第一个$后的2a代表算法版本，第二个$后的10是代价因子（默认是10，代表2的10次方次哈希），第三个$后的22个字符是盐，再后面是摘要。所以说，我们不需要使用单独的数据库字段来保存盐。
  >
  >**$2a$10$wPWdQwfQO2lMxqSIb6iCROXv7lKnQq5XdMO96iCYCj7boK9pk6QPC**
  >第三，代价因子的值越大，BCrypt哈希的耗时越久。因此，对于代价因子的值，更建议的实践是，根据用户的忍耐程度和硬件，设置一个尽可能大的值。
  >
  >最后，我们需要注意的是，虽然黑客已经很难通过彩虹表来破解密码了，但是仍然有可能暴力破解密码，也就是对于同一个用户名使用常见的密码逐一尝试登录。因此，除了做好密码哈希保存的工作外，我们还要建设一套完善的安全防御机制，在感知到暴力破解危害的时候，开启短信验证、图形验证码、账号暂时锁定等防御机制来抵御暴力破解。

- 姓名和身份证

  >密文（加密后的文本）服务手中
  >
  >IV+密钥 （加密的秘钥）加密中心手中
  >
  >AAD（用户的密码）用户手中

## HTTPS

>建立HTTPS连接的过程，首先是TCP握手，然后是TLS握手的一系列工作，包括：
>
>1. 客户端告知服务端自己支持的密码套件（比如TLS_RSA_WITH_AES_256_GCM_SHA384，其中RSA是密钥交换的方式，AES_256_GCM是加密算法，SHA384是消息验证摘要算法），提供客户端随机数。
>2. 服务端应答选择的密码套件，提供服务端随机数。
>3. 服务端发送CA证书给客户端，客户端验证CA证书（后面详细说明）。
>4. 客户端生成PreMasterKey，并使用非对称加密+公钥加密PreMasterKey。
>5. 客户端把加密后的PreMasterKey传给服务端。
>6. 服务端使用非对称加密+私钥解密得到PreMasterKey，并使用PreMasterKey+两个随机数，生成MasterKey。
>7. 客户端也使用PreMasterKey+两个随机数生成MasterKey。
>8. 客户端告知服务端之后将进行加密传输。
>9. 客户端使用MasterKey配合对称加密算法，进行对称加密测试。
>10. 服务端也使用MasterKey配合对称加密算法，进行对称加密测试。
>
>接下来，客户端和服务端的所有通信都是加密通信，并且数据通过签名确保无法篡改。你可能会问，客户端怎么验证CA证书呢？
>
>其实，CA证书是一个证书链，你可以看一下上图的左边部分：
>
>- 从服务端拿到的CA证书是用户证书，我们需要通过证书中的签发人信息找到上级中间证书，再网上找到根证书。
>- 根证书只有为数不多的权威机构才能生成，一般预置在OS中，根本无法伪造。
>- 找到根证书后，提取其公钥来验证中间证书的签名，判断其权威性。
>- 最后再拿到中间证书的公钥，验证用户证书的签名。
>
>这，就验证了用户证书的合法性，然后再校验其有效期、域名等信息进一步验证有效性。

# 缓存

## 常用缓存策略

- Cache-Aside

  >1. 应用程序首先检查缓存。
  >2. 如果在缓存中找到，表示已经命中缓存。数据被读取并返回给应用程序。
  >3. 如果在缓存中没有找到，则未命中缓存。应用程序必须做一些额外的工作，它需要查询数据库来读取数据，将数据返回给客户端，然后还要将数据存储在缓存中，这样对相同数据的后续读取可以命中缓存。

- Read-Though

  >Read-through策略中缓存与数据库保持一致。当缓存没命中，它从数据库加载数据，填充缓存并将其返回给应用程序。
  >
  >Read-through和cache-aside非常相似，但至少有两个关键的区别:
  >1、在cache-aside中应用程序负责从数据库获取数据并写入缓存。在read-through中，这个逻辑通常由第三方库或缓存独立来完成。
  >2、不像cache-aside，read-through中的数据模型不能与数据库中的数据模型不同。
  >Read-through在读负载很高，即相同的数据被多次请求的情况下效果很好。缺点是，当数据第一次被请求时，它总是会导致缓存丢失，必须通过数据库加载数据。需要开发人员通过人工发起查询，“预热””缓存来解决这个问题。与cache-aside一样，缓存和数据库之间也可能出现数据不一致的情况

- Write-Through

  >数据首先写入缓存，然后写入数据库。缓存与数据库保持一致，写操作总是通过缓存到主数据库。

- Write-Around

  >数据直接写入数据库，只有被读取的数据才会进入缓存。

- Write-Back

  >应用程序将数据写入缓存，并立即返回客户端，经过一段延迟后，它将数据写回数据库。

## 堆外缓存

- netty、RocketMQ的ByteBuffer.allocateDirect()方法，通过JVM的MaxDirectMemorySize来限制程序调用的直接缓存，在内存回收实例时堆外内存也会被一并释放

# 服务网关

>鉴权、流控、日志、安防、负载均衡、灰度发布全部放在网关

# 链路追踪

## 埋点信息

入口->RPC1(A->B), RPC2(B->C),RPC3(B->D),RPC4(A->D)->返回

- RPC 中的角色与过程：Client、Server、Trace

  >每一次完整的 RPC 调用中，都包含了以下四个过程：
  >
  >- Client Send：客户端发起请求
  >- Server Recv：服务端接收请求
  >- Server Send：服务端返回结果
  >- Client Recv：客户端接收结果
  >
  >这四个交互过程就是 Mtrace 主要的埋点过程。

- 调用链路中的标记信息：TraceId、SpanId

  >每条完整的链路一个唯一 id 作为标记。这个标记在整个 Trace 过程中都会携带，这样，在 A、B、C、D、E 分别上报自己的埋点信息时，就可以通过 **traceid** 关联起一条完整的调用链路。
  >
  >同时，Mtrace 还会给每个环节（A、B、C、D、E）一个标记(**spanName**)，表示调用的不同环节，并且用序号(**spanId**)表示调用的发起顺序。
  >
  >在这个例子中，调用发起的顺序为 RPC1 > RPC2 > RPC3 > RPC4，对应到每次 RPC Call 的 server 端的 spanId 即 0.1 > 0.1.1 > 0.1.2 > 0.2。

## 工作原理

- 串行模型

  >通常的服务框架设计中，同一个线程同一时间只会处理一个请求，因此可以使用 Thread Local 变量存储 client 及 server 的 Span 对象。

- 并行模型

  >如果在处理请求时并发地执行了多个 client span，则多个 client span 会共享 server span（，并按照启动顺序分别生成自己的 client span。client span id 的赋值是根据 server span 里的计数器来的(atomicInt.incrementAndGet() )，所以不用担心重复的问题。

- 异步模型

  >如果服务端使用异步+回调的方式处理请求，需要把 span 参数传递给回调线程，否则 span 信息会丢失。

# 流控

## 方案

- 算法

  >- 令牌桶算法
  >
  >  1. 每秒放入1/r个令牌，比如每0.1秒放入1个令牌，每秒就可以放入10个令牌
  >
  >  2. 桶中最多放入b个令牌，比如最多可以放入100个令牌
  >  3. 一个n字节的请求消耗n个令牌
  >  4. 桶中令牌数小于n，该数据包执行限流
  >
  >- 漏桶算法
  >  1. 可以以任意速率向桶中流入水滴
  >  2. 桶容量固定不变，桶满则溢出
  >  3. 按照固定速率从桶中流出水滴
  >
  >这俩算法的区别在于，令牌桶算法限制了流入速率，可以应对一定的突发流量，漏桶限制的流出速率而且这种速率固定不变，不能应对突发流量
  >
  >- 计数器算法
  >
  >  来一个记一次数，每个时间单位清零一次
  >
  >  缺点：限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量
  >
  >- 滑动窗口
  >
  >  维护K+1的循环队列，有新的请求到来时，我们将与这个新请求的时间间隔超过1s的请求，从队列中删除。然后我们再来看循环队列中是否有空闲位置。如果有，则把新请求存储在队列尾部，如果没有，则说明1s内的请求次数已经超过了限流值K，所以这个请求被拒绝服务。

- 接入层限流

  >nginx+redis+lua，对url限流

- 应用层限流

  >针对特定业务的限流
  >
  >- 活动分时段限流
  >- 答题验证
  >- 基于消息队列


# 定时任务

- linux的crontab
- jdk的定时任务
  - Thread死循环+sleep
  - Timer的TimerTask
- spring
  - spring task @Scheduled
- 分布式定时任务
  - xxl-job(大众点评)
  - elastic-job（当当点评）
  - Saturn（唯品会）
  - TBSchedule（阿里）

# 接口设计

## 接口兼容

```java
//老接口
void oldService(A,B){
  //兼容新接口，传个null代替C
  newService(A,B,null);
}

//新接口，暂时不能删掉老接口，需要做兼容。
void newService(A,B,C){
  ...
}
```

## 幂等

- insert前先select，如果数据已存在就执行update

- 加悲观锁

  ```sql
  update user amount = amount-100 where id=123;
  #多次相同的请求，可能会导致用户A的余额变成负数。这种情况，用户A来可能要哭了
  
  #通常情况下通过如下sql锁住单行数据
  select * from user id=123 for update;
  ```

  悲观锁需要在同一个事务操作过程中锁住一行数据，如果事务耗时比较长，会造成大量的请求等待，影响接口性能。此外，每次请求接口很难保证都有相同的返回值，所以不适合幂等性设计场景，但是在防重场景中是可以的使用的。

  > 需要特别注意的是：如果使用的是mysql数据库，存储引擎必须用innodb，因为它才支持事务。此外，这里id字段一定要是主键或者唯一索引，不然会锁住整张表。

  > 防重设计主要为了避免产生重复数据，对接口返回没有太多要求。而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。

- 加乐观锁

  ```sql
  # 将id,verison作为条件
  select id,amount,version from user id=123;
  # 第一次更新成功
  update user set amount=amount+100,version=version+1
  where id=123 and version=1;
  # 第二次更新不成功
  update user set amount=amount+100,version=version+1
  where id=123 and version=1;
  ```

- 加唯一索引

- 建防重表

  有时候表中并非所有的场景都不允许产生重复的数据，只有某些特定场景才不允许。这时候，直接在表中加唯一索引，显然是不太合适的。

  针对这种情况，我们可以通过`建防重表`来解决问题。

  该表可以只包含两个字段：`id` 和 `唯一索引`，唯一索引可以是多个字段比如：name、code等组合起来的唯一标识

  > 需要特别注意的是：防重表和业务表必须在同一个数据库中，并且操作要在同一个事务中。

- 状态机

  很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态。如果这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。

  > 主要特别注意的是，该方案仅限于要更新的`表有状态字段`，并且刚好要更新`状态字段`的这种特殊情况，并非所有场景都适用。

- 分布式锁

  `redis`或zookeeper

  目前主要有三种方式实现redis的分布式锁：

  1. setNx命令
  2. set命令
  3. Redission框架

- 获取token

  需要两次请求才能完成一次业务操作。

  1. 第一次请求获取`token`
  2. 第二次请求带着这个`token`，完成业务操作。

# 监控

- 监控哪些信息

  >- 主机层面，对CPU、内存、磁盘、网络等资源做监控。如果应用部署在虚拟机或Kubernetes集群中，那么除了对物理机做基础资源监控外，还要对虚拟机或Pod做同样的监控。监控层数取决于应用的部署方案，有一层OS就要做一层监控。
  >- 网络层面，需要监控专线带宽、交换机基本情况、网络延迟。
  >- 所有的中间件和存储都要做好监控
  >- 应用层面，需要监控JVM进程的类加载、内存、GC、线程等常见指标

# 存储

- 各种数据库对比

| 数据库   | 适合                                                         | 不适合                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| redis    | 按照key值单条查询                                            | key搜索，keys 命令对 Key 的搜索，需要做全表扫描。            |
| InfluxDB | 保存指标数据按照时间聚合查询  **数据监控**、 **服务器监控：**、**事件跟踪**、**日志监控**、**用户行为**、**DevOps** | 不支持数据更新操作,数据只能和时间戳关联，tag需要有限而不是类似于url这种每次都不一样的 |
| ES       | 全文搜索                                                     | ES 的索引是文档维度的，所以不适用于频繁更新的 OLTP 业务      |

- 各种数据库原理

  >LSM
  >
  >TSM
  >
  >B+
  >
  >倒排
  >
  >FST

一个典型的数据库选型

![](https://img-blog.csdnimg.cn/d5ca038ced5f4cf784b6dd54c0a914fd.png)

- 需要根据主键查询单条数据，可以从 MySQL Sharding 集群或 Redis 查询，如果对实时性要求不高也可以从 ES 查询。
- 按照多个条件搜索订单的场景，可以从 MySQL 索引表查询出主键列表，然后再根据主键从 MySQL Sharding 集群或 Redis 获取数据详情。
- 各种后台系统需要使用比较复杂的搜索条件，甚至全文搜索来查询订单数据，或是定时分析任务需要一次查询大量数据，这些场景对数据实时性要求都不高，可以到 ES 进行搜索。
- 此外，MySQL 中的数据可以归档，我们可以在 ES 中保留更久的数据，而且查询历史数据一般并发不会很大，可以统一路由到 ES 查询。监控系统或后台报表系统需要呈现业务监控图表或表格，可以把请求路由到 InfluxDB 查询。

# 系统设计

[秒杀](https://mp.weixin.qq.com/s/l05_28xe6O4vZUQEmnu2Ug)	 [微博点赞系统设计思路](https://mp.weixin.qq.com/s/GwCkm-Ba_7NuZFFCQBnD3g)     [redis实现的点赞](https://mp.weixin.qq.com/s/fDOmWWNKHBOWx6ITcsAZeQ)

## 未支付自动取消订单

- 方案1

  每隔n分钟搜索订单时间大于15分钟未支付的订单状态改为取消，单机使用springtask、集群使用分布式任务调度。

  优点：简单

  缺点：n分钟扫描一次订单状态不能及时更新，n秒的话订单表查询压力大

- 方案二

  redis6的客户端缓存监听方案，监听redis6数据变化。创建订单时额外缓存到redis，放入set类型（key为订单编号，value为实例id，超时时间15分钟），超时时取消，完成时移除缓存

  优点：及时有效，集群友好（哪个实例创建哪个实例取消）

  缺点：基于长连接，连接重启后客户端缓存监听机制会失效，需要手动补偿；实例数量变化以后需要重新做分配；需要升级redis6

- 方案三

  延迟消息，死信队列，在15分钟内没有被消费就送到死信队列，由死信队列处理

  优点：消息及时投递，集群友好，代码量小，不需要额外集群调度，也不绑定具体实例

  缺点：需要额外关注幂等性等MQ自身引起的问题

## 手机扫码登录

1. 访问PC端二维码生成页面，PC端请求服务端获取`二维码ID`

2. 服务端生成相应的`二维码ID`，设置二维码的过期时间，状态等。

3. PC获取`二维码ID`，生成相应的二维码。

4. 手机端扫描二维码，获取`二维码ID`。

5. 手机端将`手机端token`和`二维码ID`发送给服务端，确认登录。

6. 服务端校验`手机端token`，根据`手机端token`和`二维码ID`生成`PC端token`

7. PC端通过轮询方式请求服务端，通过`二维码ID`获取二维码状态，如果已成功，返回`PC token`，登录成功。

## 1000w用户抽奖10人

- 方案一

  MySQL数据库硬查询，random limit 10

  缺点：执行时间很长，数10秒级别

- 方案二

  offset=随机数*数量作为下标，然后limit offset,1

  缺点：两条SQL，原子性问题，而且可能会重复中奖

- 方案三

  将用户id放入redis set，redis set做集合的随机弹出，因为弹出了所以不会重复，然后根据弹出的id执行数据库无论是查询还是用in查询都会比较快。

  缺点：查询数据库还是会有比较慢的情况

- 方案四

  纯采用redis，将除id以外的其他值也存入redis

  缺点：需要比较富裕的redis内存

## 如何防止掉单

[原文](https://mp.weixin.qq.com/s/zMRXR-kVqvN5rqQxsV2HSA)

订单支付的完整流程：

>1. 用户从电商应用点击支付，客户端向服务端发起支付请求
>2. 支付服务会向第三方的支付渠道发起支付，支付渠道会响应对应的url
>3. 以APP为例，客户端通常是会拉起对应的钱包，用户跳到对应的钱包
>4. 用户在钱包里完成支付
>5. 用户完成支付后，跳转回对应的电商APP
>6. 客户端轮询订单服务，获取订单状态
>7. 支付渠道回调支付服务，通知支付结果
>8. 支付服务通知订单服务，更新订单状态

什么是掉单？简单说，就是支付的状态没有同步到，或者没有及时同步到。

>1. 支付渠道的支付回调
>
>  发生了一些异常，导致支付服务没有收到支付渠道的回调通知
>
>2. 支付服务通知订单服务
>
>  服务内部出现异常，导致支付状态没有同步到订单服务
>
>3. 客户端获取订单状态
>
>  客户端通常是轮询获取状态，可能会在轮询时间内没有获取到订单状态，结果用户看到未支付
>
>其中1可以称之为外部掉单，2和3可以称之为内部掉单。

防内部

>服务端（支付服务调用订单服务时）：
>
>- 同步（接口+重试）+异步（消息队列）
>
>客户端（支付完成后客户端调用）：
>
>- 倒计时一段时间客户端显示未支付，但是一旦服务端的订单状态变更了，也要尽可能同步到客户端，不能让用户一直看到未支付。

防外部

>相比较内部掉单，外部掉单发生的概率就大很多，毕竟和外部渠道的对接，不可控的因素更多。要防止外部掉单，核心就是四个字：“`主动查询`”，如果只是等待第三方的回调通知，风险还是比较大的，支付服务要主动向第三方查询支付状态，即使有什么异常，也能及时感知到。
>
>- 定时任务（时间不好确定、数据库有压力）
>- 延时消息（RocketMQ，无需扫表，对数据库压力较小）

## 文档协同编辑

https://developer.aliyun.com/article/738238

https://cloud.tencent.com/developer/article/1925610
